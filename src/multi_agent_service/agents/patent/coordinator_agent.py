"""Patent Coordinator Agent implementation for managing patent analysis workflows."""

import asyncio
import logging
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from uuid import uuid4

from .base import PatentBaseAgent
from ..coordinator_agent import CoordinatorAgent
from ...models.base import UserRequest, AgentResponse, Action, CollaborationResult, Conflict
from ...models.config import AgentConfig
from ...models.enums import AgentType, WorkflowStatus
from ...services.model_client import BaseModelClient
from ...workflows.state_management import WorkflowStateManager
# AgentRouter will be imported dynamically to avoid circular imports


logger = logging.getLogger(__name__)


class PatentCoordinatorAgent(CoordinatorAgent):
    """ä¸“åˆ©åè°ƒAgentï¼Œè´Ÿè´£ç®¡ç†ä¸“åˆ©åˆ†æå·¥ä½œæµçš„æ‰§è¡Œå’Œåè°ƒ."""
    
    def __init__(self, config: AgentConfig, model_client: BaseModelClient, 
                 state_manager: Optional[WorkflowStateManager] = None,
                 agent_router: Optional[Any] = None):
        """åˆå§‹åŒ–ä¸“åˆ©åè°ƒAgent."""
        super().__init__(config, model_client)
        
        # ä¸“åˆ©åˆ†æç‰¹å®šçš„åè°ƒé…ç½®
        self.patent_workflow_config = {
            'data_collection_agents': ['patent_data_collection_agent'],
            'search_agents': ['patent_search_agent'],
            'analysis_agents': ['patent_analysis_agent'],
            'report_agents': ['patent_report_agent']
        }
        
        # ä¸“åˆ©åˆ†æå…³é”®è¯
        self.patent_coordination_keywords = [
            "ä¸“åˆ©åˆ†æ", "ä¸“åˆ©æ£€ç´¢", "ä¸“åˆ©æŠ¥å‘Š", "æŠ€æœ¯åˆ†æ", "ç«äº‰åˆ†æ",
            "ä¸“åˆ©è¶‹åŠ¿", "ä¸“åˆ©æ•°æ®", "çŸ¥è¯†äº§æƒåˆ†æ", "æŠ€æœ¯å‘å±•",
            "patent analysis", "patent search", "patent report", 
            "technology analysis", "competitive analysis"
        ]
        
        # ä¸“åˆ©å·¥ä½œæµç±»å‹
        self.patent_workflow_types = {
            "comprehensive_analysis": "å…¨é¢ä¸“åˆ©åˆ†æå·¥ä½œæµ",
            "quick_search": "å¿«é€Ÿä¸“åˆ©æ£€ç´¢å·¥ä½œæµ", 
            "trend_analysis": "ä¸“åˆ©è¶‹åŠ¿åˆ†æå·¥ä½œæµ",
            "competitive_analysis": "ç«äº‰åˆ†æå·¥ä½œæµ",
            "report_generation": "ä¸“åˆ©æŠ¥å‘Šç”Ÿæˆå·¥ä½œæµ"
        }
        
        # å·¥ä½œæµçŠ¶æ€ç®¡ç†å™¨
        self.state_manager = state_manager or WorkflowStateManager()
        
        # Agentè·¯ç”±å™¨
        self.agent_router = agent_router
        
        # æ´»è·ƒçš„ä¸“åˆ©åˆ†æä»»åŠ¡
        self.active_patent_tasks: Dict[str, Dict[str, Any]] = {}
        
        # ä¸“åˆ©Agentèƒ½åŠ›æ˜ å°„
        self.patent_agent_capabilities = {
            "patent_data_collection_agent": [
                "ä¸“åˆ©æ•°æ®æ”¶é›†", "å¤šæ•°æ®æºé›†æˆ", "æ•°æ®æ¸…æ´—", "æ•°æ®ç¼“å­˜"
            ],
            "patent_search_agent": [
                "CNKIå­¦æœ¯æœç´¢", "åšæŸ¥AIæœç´¢", "ç½‘é¡µçˆ¬å–", "æœç´¢ç»“æœå¢å¼º"
            ],
            "patent_analysis_agent": [
                "è¶‹åŠ¿åˆ†æ", "æŠ€æœ¯åˆ†ç±»", "ç«äº‰åˆ†æ", "åœ°åŸŸåˆ†æ", "æ·±åº¦æ´å¯Ÿ"
            ],
            "patent_report_agent": [
                "æŠ¥å‘Šç”Ÿæˆ", "å›¾è¡¨åˆ¶ä½œ", "æ¨¡æ¿æ¸²æŸ“", "å¤šæ ¼å¼å¯¼å‡º"
            ]
        }
        
        # ä¸“åˆ©å·¥ä½œæµæ‰§è¡Œç­–ç•¥
        self.execution_strategies = {
            "sequential": self._execute_sequential_workflow,
            "parallel": self._execute_parallel_workflow,
            "hierarchical": self._execute_hierarchical_workflow,
            "hybrid": self._execute_hybrid_workflow
        }
    
    async def can_handle_request(self, request: UserRequest) -> float:
        """åˆ¤æ–­æ˜¯å¦èƒ½å¤„ç†ä¸“åˆ©åè°ƒè¯·æ±‚."""
        content = request.content.lower()
        
        # æ£€æŸ¥ä¸“åˆ©åè°ƒå…³é”®è¯
        keyword_matches = sum(1 for keyword in self.patent_coordination_keywords if keyword in content)
        keyword_score = min(keyword_matches * 0.3, 0.8)
        
        # æ£€æŸ¥å¤æ‚æ€§æŒ‡æ ‡ï¼ˆéœ€è¦åè°ƒçš„ä¸“åˆ©ä»»åŠ¡ï¼‰
        complexity_indicators = [
            "å…¨é¢", "ç»¼åˆ", "å®Œæ•´", "æ·±åº¦", "å¤šç»´åº¦", "ç³»ç»Ÿæ€§",
            "comprehensive", "complete", "in-depth", "systematic"
        ]
        complexity_score = 0.4 if any(indicator in content for indicator in complexity_indicators) else 0
        
        # æ£€æŸ¥å¤šAgentéœ€æ±‚
        multi_agent_patterns = [
            r"(æ•°æ®æ”¶é›†|æ£€ç´¢|æœç´¢).*?(åˆ†æ|æŠ¥å‘Š)",
            r"(åˆ†æ|å¤„ç†).*?(æŠ¥å‘Š|å±•ç¤º)",
            r"(ä¸“åˆ©|æŠ€æœ¯).*?(å…¨é¢|ç»¼åˆ).*?(åˆ†æ|ç ”ç©¶)",
            r"éœ€è¦.*?(å¤šä¸ª|å„ç§|ä¸åŒ).*?(æ•°æ®|ä¿¡æ¯|åˆ†æ)"
        ]
        
        import re
        pattern_score = 0
        for pattern in multi_agent_patterns:
            if re.search(pattern, content):
                pattern_score += 0.3
        
        # åŸºäºçˆ¶ç±»åè°ƒèƒ½åŠ›çš„åŸºç¡€åˆ†æ•°
        base_score = await super().can_handle_request(request)
        
        # ç»¼åˆè®¡ç®—ä¸“åˆ©åè°ƒç½®ä¿¡åº¦
        total_score = min(
            base_score * 0.3 + keyword_score + complexity_score + pattern_score, 
            1.0
        )
        
        return max(total_score, 0.0)
    
    async def get_capabilities(self) -> List[str]:
        """è·å–ä¸“åˆ©åè°ƒAgentçš„èƒ½åŠ›åˆ—è¡¨."""
        base_capabilities = await super().get_capabilities()
        patent_capabilities = [
            "ä¸“åˆ©å·¥ä½œæµåè°ƒ",
            "ä¸“åˆ©Agentè°ƒåº¦",
            "ä¸“åˆ©æ•°æ®æµç®¡ç†",
            "ä¸“åˆ©åˆ†æè´¨é‡æ§åˆ¶",
            "ä¸“åˆ©æŠ¥å‘Šæ•´åˆ",
            "ä¸“åˆ©ä»»åŠ¡ç›‘æ§"
        ]
        return base_capabilities + patent_capabilities
    
    async def estimate_processing_time(self, request: UserRequest) -> int:
        """ä¼°ç®—ä¸“åˆ©åè°ƒå¤„ç†æ—¶é—´."""
        content = request.content.lower()
        
        # å¿«é€Ÿæ£€ç´¢ï¼š60-90ç§’
        if any(word in content for word in ["å¿«é€Ÿ", "ç®€å•", "åŸºæœ¬"]):
            return 75
        
        # å…¨é¢åˆ†æï¼š180-300ç§’
        if any(word in content for word in ["å…¨é¢", "æ·±åº¦", "å®Œæ•´", "ç»¼åˆ"]):
            return 240
        
        # æŠ¥å‘Šç”Ÿæˆï¼š120-180ç§’
        if any(word in content for word in ["æŠ¥å‘Š", "æ–‡æ¡£", "å±•ç¤º"]):
            return 150
        
        # é»˜è®¤ä¸“åˆ©åè°ƒæ—¶é—´
        return 120
    
    async def _process_request_specific(self, request: UserRequest) -> AgentResponse:
        """å¤„ç†ä¸“åˆ©åè°ƒè¯·æ±‚."""
        try:
            # åˆ†æä¸“åˆ©ä»»åŠ¡ç±»å‹å’Œå¤æ‚åº¦
            task_analysis = await self._analyze_patent_task(request.content)
            
            # ç¡®å®šæ‰€éœ€çš„ä¸“åˆ©Agent
            required_agents = await self._identify_required_patent_agents(request.content, task_analysis)
            
            # é€‰æ‹©æ‰§è¡Œç­–ç•¥
            execution_strategy = self._determine_patent_execution_strategy(task_analysis, required_agents)
            
            # åˆ›å»ºä¸“åˆ©å·¥ä½œæµæ‰§è¡Œä¸Šä¸‹æ–‡
            workflow_context = await self._create_patent_workflow_context(
                request, task_analysis, required_agents, execution_strategy
            )
            
            # æ‰§è¡Œä¸“åˆ©å·¥ä½œæµ
            coordination_result = await self._execute_patent_workflow(
                workflow_context, execution_strategy
            )
            
            # ç”Ÿæˆä¸“åˆ©åè°ƒå“åº”
            response_content = await self._generate_patent_coordination_response(
                coordination_result, workflow_context
            )
            
            # ç”Ÿæˆåç»­åŠ¨ä½œ
            next_actions = self._generate_patent_coordination_actions(
                coordination_result, workflow_context
            )
            
            return AgentResponse(
                agent_id=self.agent_id,
                agent_type=self.agent_type,
                response_content=response_content,
                confidence=0.95,
                next_actions=next_actions,
                collaboration_needed=False,
                metadata={
                    "workflow_type": execution_strategy,
                    "required_agents": required_agents,
                    "task_analysis": task_analysis,
                    "coordination_id": coordination_result.collaboration_id,
                    "patent_task_type": workflow_context.get("task_type"),
                    "processed_at": datetime.now().isoformat()
                }
            )
            
        except Exception as e:
            self.logger.error(f"Patent coordination failed: {str(e)}")
            return AgentResponse(
                agent_id=self.agent_id,
                agent_type=self.agent_type,
                response_content=f"ä¸“åˆ©åˆ†æåè°ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}",
                confidence=0.0,
                collaboration_needed=False,
                metadata={"error": str(e), "error_type": "coordination_failure"}
            )
    
    async def _analyze_patent_task(self, content: str) -> Dict[str, Any]:
        """åˆ†æä¸“åˆ©ä»»åŠ¡ç±»å‹å’Œå¤æ‚åº¦."""
        content_lower = content.lower()
        
        # ä»»åŠ¡ç±»å‹è¯†åˆ«
        task_type = "comprehensive_analysis"  # é»˜è®¤
        
        if any(word in content_lower for word in ["æ£€ç´¢", "æœç´¢", "æŸ¥æ‰¾"]):
            task_type = "quick_search"
        elif any(word in content_lower for word in ["è¶‹åŠ¿", "å‘å±•", "å˜åŒ–"]):
            task_type = "trend_analysis"
        elif any(word in content_lower for word in ["ç«äº‰", "å¯¹æ¯”", "æ¯”è¾ƒ"]):
            task_type = "competitive_analysis"
        elif any(word in content_lower for word in ["æŠ¥å‘Š", "æ–‡æ¡£", "å±•ç¤º"]):
            task_type = "report_generation"
        
        # å¤æ‚åº¦åˆ†æ
        complexity_factors = {
            "data_sources": len([s for s in ["cnki", "ä¸“åˆ©", "å­¦æœ¯", "ç½‘é¡µ"] if s in content_lower]),
            "analysis_depth": 1 if any(word in content_lower for word in ["æ·±åº¦", "è¯¦ç»†", "å…¨é¢"]) else 0,
            "output_formats": len([f for f in ["æŠ¥å‘Š", "å›¾è¡¨", "æ–‡æ¡£", "pdf"] if f in content_lower]),
            "time_range": 1 if any(word in content_lower for word in ["å¹´", "æœˆ", "å†å²", "è¶‹åŠ¿"]) else 0
        }
        
        total_complexity = sum(complexity_factors.values())
        
        if total_complexity >= 4:
            complexity_level = "high"
        elif total_complexity >= 2:
            complexity_level = "medium"
        else:
            complexity_level = "low"
        
        return {
            "task_type": task_type,
            "complexity_level": complexity_level,
            "complexity_factors": complexity_factors,
            "complexity_score": total_complexity,
            "estimated_duration": self._estimate_task_duration(task_type, complexity_level)
        }
    
    async def _identify_required_patent_agents(self, content: str, task_analysis: Dict[str, Any]) -> List[str]:
        """è¯†åˆ«æ‰€éœ€çš„ä¸“åˆ©Agent."""
        content_lower = content.lower()
        required_agents = []
        
        task_type = task_analysis.get("task_type", "comprehensive_analysis")
        
        # æ ¹æ®ä»»åŠ¡ç±»å‹ç¡®å®šåŸºç¡€Agentéœ€æ±‚
        if task_type == "quick_search":
            required_agents = ["patent_search_agent"]
        elif task_type == "trend_analysis":
            required_agents = ["patent_data_collection_agent", "patent_analysis_agent"]
        elif task_type == "competitive_analysis":
            required_agents = ["patent_data_collection_agent", "patent_search_agent", "patent_analysis_agent"]
        elif task_type == "report_generation":
            required_agents = ["patent_analysis_agent", "patent_report_agent"]
        else:  # comprehensive_analysis
            required_agents = [
                "patent_data_collection_agent",
                "patent_search_agent", 
                "patent_analysis_agent",
                "patent_report_agent"
            ]
        
        # æ ¹æ®å†…å®¹è¿›ä¸€æ­¥è°ƒæ•´
        if any(word in content_lower for word in ["æ•°æ®", "æ”¶é›†", "è·å–"]):
            if "patent_data_collection_agent" not in required_agents:
                required_agents.insert(0, "patent_data_collection_agent")
        
        if any(word in content_lower for word in ["æœç´¢", "æ£€ç´¢", "cnki", "åšæŸ¥"]):
            if "patent_search_agent" not in required_agents:
                required_agents.append("patent_search_agent")
        
        if any(word in content_lower for word in ["åˆ†æ", "è¶‹åŠ¿", "ç«äº‰"]):
            if "patent_analysis_agent" not in required_agents:
                required_agents.append("patent_analysis_agent")
        
        if any(word in content_lower for word in ["æŠ¥å‘Š", "æ–‡æ¡£", "å›¾è¡¨"]):
            if "patent_report_agent" not in required_agents:
                required_agents.append("patent_report_agent")
        
        return required_agents
    
    def _determine_patent_execution_strategy(self, task_analysis: Dict[str, Any], 
                                           required_agents: List[str]) -> str:
        """ç¡®å®šä¸“åˆ©å·¥ä½œæµæ‰§è¡Œç­–ç•¥."""
        task_type = task_analysis.get("task_type")
        complexity_level = task_analysis.get("complexity_level")
        agent_count = len(required_agents)
        
        # å¿«é€Ÿæœç´¢ä½¿ç”¨é¡ºåºæ‰§è¡Œ
        if task_type == "quick_search":
            return "sequential"
        
        # é«˜å¤æ‚åº¦æˆ–å¤šAgentä½¿ç”¨åˆ†å±‚æ‰§è¡Œ
        if complexity_level == "high" or agent_count > 3:
            return "hierarchical"
        
        # ä¸­ç­‰å¤æ‚åº¦ä½¿ç”¨æ··åˆæ‰§è¡Œ
        if complexity_level == "medium" or agent_count > 2:
            return "hybrid"
        
        # ç®€å•ä»»åŠ¡ä½¿ç”¨å¹¶è¡Œæ‰§è¡Œ
        return "parallel"
    
    async def _create_patent_workflow_context(self, request: UserRequest,
                                            task_analysis: Dict[str, Any],
                                            required_agents: List[str],
                                            execution_strategy: str) -> Dict[str, Any]:
        """åˆ›å»ºä¸“åˆ©å·¥ä½œæµæ‰§è¡Œä¸Šä¸‹æ–‡."""
        workflow_id = str(uuid4())
        
        context = {
            "workflow_id": workflow_id,
            "request": request,
            "task_type": task_analysis.get("task_type"),
            "complexity_level": task_analysis.get("complexity_level"),
            "required_agents": required_agents,
            "execution_strategy": execution_strategy,
            "start_time": datetime.now(),
            "shared_data": {},
            "agent_results": {},
            "status": "initialized"
        }
        
        # è®°å½•æ´»è·ƒä»»åŠ¡
        self.active_patent_tasks[workflow_id] = context
        
        return context
    
    async def _execute_patent_workflow(self, workflow_context: Dict[str, Any],
                                     execution_strategy: str) -> CollaborationResult:
        """æ‰§è¡Œä¸“åˆ©å·¥ä½œæµ."""
        workflow_id = workflow_context["workflow_id"]
        
        try:
            # æ›´æ–°çŠ¶æ€
            workflow_context["status"] = "running"
            
            # æ ¹æ®ç­–ç•¥æ‰§è¡Œå·¥ä½œæµ
            strategy_func = self.execution_strategies.get(execution_strategy, 
                                                        self._execute_sequential_workflow)
            
            result = await strategy_func(workflow_context)
            
            # æ›´æ–°çŠ¶æ€
            workflow_context["status"] = "completed"
            workflow_context["end_time"] = datetime.now()
            
            return result
            
        except Exception as e:
            workflow_context["status"] = "failed"
            workflow_context["error"] = str(e)
            workflow_context["end_time"] = datetime.now()
            
            self.logger.error(f"Patent workflow {workflow_id} failed: {str(e)}")
            
            # ä½¿ç”¨ä¸“é—¨çš„å¤±è´¥å¤„ç†æœºåˆ¶
            return await self._handle_coordination_failure(workflow_context, e)
        
        finally:
            # æ¸…ç†æ´»è·ƒä»»åŠ¡
            if workflow_id in self.active_patent_tasks:
                del self.active_patent_tasks[workflow_id]
    
    async def _execute_sequential_workflow(self, workflow_context: Dict[str, Any]) -> CollaborationResult:
        """æ‰§è¡Œé¡ºåºä¸“åˆ©å·¥ä½œæµ."""
        workflow_id = workflow_context["workflow_id"]
        required_agents = workflow_context["required_agents"]
        request = workflow_context["request"]
        
        results = []
        accumulated_data = request.context.copy()
        
        for i, agent_id in enumerate(required_agents):
            try:
                # åˆ›å»ºAgentè¯·æ±‚
                agent_request = UserRequest(
                    content=request.content,
                    user_id=request.user_id,
                    context=accumulated_data,
                    priority=request.priority
                )
                
                # è°ƒç”¨Agentï¼ˆä½¿ç”¨å¸¦é‡è¯•å’Œé™çº§çš„çœŸå®è°ƒç”¨ï¼‰
                agent_result = await self._call_patent_agent_with_fallback(agent_id, agent_request)
                results.append(agent_result)
                
                # æ›´æ–°ç´¯ç§¯æ•°æ®
                if hasattr(agent_result, 'metadata') and agent_result.metadata:
                    accumulated_data.update(agent_result.metadata.get("shared_data", {}))
                
                # è®°å½•Agentç»“æœ
                workflow_context["agent_results"][agent_id] = agent_result
                
                self.logger.info(f"Sequential step {i+1}/{len(required_agents)} completed: {agent_id}")
                
            except Exception as e:
                self.logger.error(f"Sequential step failed for agent {agent_id}: {str(e)}")
                error_result = AgentResponse(
                    agent_id=agent_id,
                    agent_type=AgentType.PATENT_COORDINATOR,
                    response_content=f"Agent {agent_id} æ‰§è¡Œå¤±è´¥: {str(e)}",
                    confidence=0.0,
                    metadata={"error": str(e)}
                )
                results.append(error_result)
                break
        
        # åŒæ­¥Agentæ•°æ®
        await self._synchronize_agent_data(workflow_context, results)
        
        # éªŒè¯å“åº”è´¨é‡
        validation_result = await self._validate_agent_responses(results)
        workflow_context["validation_result"] = validation_result
        
        # æ•´åˆé¡ºåºæ‰§è¡Œç»“æœ
        final_result = self._integrate_sequential_patent_results(results, workflow_context)
        
        return CollaborationResult(
            collaboration_id=workflow_id,
            participating_agents=required_agents + [self.agent_id],
            final_result=final_result,
            individual_responses=results,
            consensus_reached=True,
            resolution_method="sequential_integration"
        )
    
    async def _execute_parallel_workflow(self, workflow_context: Dict[str, Any]) -> CollaborationResult:
        """æ‰§è¡Œå¹¶è¡Œä¸“åˆ©å·¥ä½œæµ."""
        workflow_id = workflow_context["workflow_id"]
        required_agents = workflow_context["required_agents"]
        request = workflow_context["request"]
        
        # åˆ›å»ºå¹¶è¡Œä»»åŠ¡
        tasks = []
        for agent_id in required_agents:
            agent_request = UserRequest(
                content=request.content,
                user_id=request.user_id,
                context=request.context.copy(),
                priority=request.priority
            )
            
            task = self._call_patent_agent_with_fallback(agent_id, agent_request)
            tasks.append(task)
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœ
        valid_results = []
        for i, result in enumerate(results):
            agent_id = required_agents[i]
            if isinstance(result, Exception):
                error_result = AgentResponse(
                    agent_id=agent_id,
                    agent_type=AgentType.PATENT_COORDINATOR,
                    response_content=f"Agent {agent_id} æ‰§è¡Œå¤±è´¥: {str(result)}",
                    confidence=0.0,
                    metadata={"error": str(result)}
                )
                valid_results.append(error_result)
            else:
                valid_results.append(result)
                workflow_context["agent_results"][agent_id] = result
        
        # åŒæ­¥Agentæ•°æ®
        await self._synchronize_agent_data(workflow_context, valid_results)
        
        # éªŒè¯å“åº”è´¨é‡
        validation_result = await self._validate_agent_responses(valid_results)
        workflow_context["validation_result"] = validation_result
        
        # æ•´åˆå¹¶è¡Œæ‰§è¡Œç»“æœ
        final_result = self._integrate_parallel_patent_results(valid_results, workflow_context)
        
        return CollaborationResult(
            collaboration_id=workflow_id,
            participating_agents=required_agents + [self.agent_id],
            final_result=final_result,
            individual_responses=valid_results,
            consensus_reached=len(valid_results) == len(required_agents),
            resolution_method="parallel_integration"
        )
    
    async def _execute_hierarchical_workflow(self, workflow_context: Dict[str, Any]) -> CollaborationResult:
        """æ‰§è¡Œåˆ†å±‚ä¸“åˆ©å·¥ä½œæµ."""
        workflow_id = workflow_context["workflow_id"]
        required_agents = workflow_context["required_agents"]
        
        # ç¬¬ä¸€å±‚ï¼šæ•°æ®æ”¶é›†
        data_agents = [agent for agent in required_agents 
                      if "data_collection" in agent or "search" in agent]
        
        # ç¬¬äºŒå±‚ï¼šåˆ†æå¤„ç†
        analysis_agents = [agent for agent in required_agents 
                          if "analysis" in agent]
        
        # ç¬¬ä¸‰å±‚ï¼šæŠ¥å‘Šç”Ÿæˆ
        report_agents = [agent for agent in required_agents 
                        if "report" in agent]
        
        all_results = []
        
        # æ‰§è¡Œç¬¬ä¸€å±‚
        if data_agents:
            layer1_context = workflow_context.copy()
            layer1_context["required_agents"] = data_agents
            layer1_result = await self._execute_parallel_workflow(layer1_context)
            all_results.extend(layer1_result.individual_responses)
        
        # æ‰§è¡Œç¬¬äºŒå±‚
        if analysis_agents:
            layer2_context = workflow_context.copy()
            layer2_context["required_agents"] = analysis_agents
            # ä¼ é€’ç¬¬ä¸€å±‚çš„ç»“æœ
            if data_agents:
                layer2_context["shared_data"].update(
                    self._extract_shared_data_from_results(layer1_result.individual_responses)
                )
            layer2_result = await self._execute_parallel_workflow(layer2_context)
            all_results.extend(layer2_result.individual_responses)
        
        # æ‰§è¡Œç¬¬ä¸‰å±‚
        if report_agents:
            layer3_context = workflow_context.copy()
            layer3_context["required_agents"] = report_agents
            # ä¼ é€’å‰é¢å±‚çš„ç»“æœ
            if analysis_agents:
                layer3_context["shared_data"].update(
                    self._extract_shared_data_from_results(layer2_result.individual_responses)
                )
            layer3_result = await self._execute_parallel_workflow(layer3_context)
            all_results.extend(layer3_result.individual_responses)
        
        # æ•´åˆåˆ†å±‚æ‰§è¡Œç»“æœ
        final_result = self._integrate_hierarchical_patent_results(all_results, workflow_context)
        
        return CollaborationResult(
            collaboration_id=workflow_id,
            participating_agents=required_agents + [self.agent_id],
            final_result=final_result,
            individual_responses=all_results,
            consensus_reached=True,
            resolution_method="hierarchical_coordination"
        )
    
    async def _execute_hybrid_workflow(self, workflow_context: Dict[str, Any]) -> CollaborationResult:
        """æ‰§è¡Œæ··åˆä¸“åˆ©å·¥ä½œæµ."""
        # æ··åˆç­–ç•¥ï¼šæ•°æ®æ”¶é›†å’Œæœç´¢å¹¶è¡Œï¼Œç„¶åé¡ºåºæ‰§è¡Œåˆ†æå’ŒæŠ¥å‘Š
        workflow_id = workflow_context["workflow_id"]
        required_agents = workflow_context["required_agents"]
        
        # åˆ†ç»„
        parallel_agents = [agent for agent in required_agents 
                          if "data_collection" in agent or "search" in agent]
        sequential_agents = [agent for agent in required_agents 
                           if "analysis" in agent or "report" in agent]
        
        all_results = []
        
        # å¹¶è¡Œæ‰§è¡Œæ•°æ®æ”¶é›†å’Œæœç´¢
        if parallel_agents:
            parallel_context = workflow_context.copy()
            parallel_context["required_agents"] = parallel_agents
            parallel_result = await self._execute_parallel_workflow(parallel_context)
            all_results.extend(parallel_result.individual_responses)
            
            # æ›´æ–°å…±äº«æ•°æ®
            workflow_context["shared_data"].update(
                self._extract_shared_data_from_results(parallel_result.individual_responses)
            )
        
        # é¡ºåºæ‰§è¡Œåˆ†æå’ŒæŠ¥å‘Š
        if sequential_agents:
            sequential_context = workflow_context.copy()
            sequential_context["required_agents"] = sequential_agents
            sequential_result = await self._execute_sequential_workflow(sequential_context)
            all_results.extend(sequential_result.individual_responses)
        
        # æ•´åˆæ··åˆæ‰§è¡Œç»“æœ
        final_result = self._integrate_hybrid_patent_results(all_results, workflow_context)
        
        return CollaborationResult(
            collaboration_id=workflow_id,
            participating_agents=required_agents + [self.agent_id],
            final_result=final_result,
            individual_responses=all_results,
            consensus_reached=True,
            resolution_method="hybrid_execution"
        )
    
    async def _call_patent_agent(self, agent_id: str, request: UserRequest) -> AgentResponse:
        """è°ƒç”¨æŒ‡å®šçš„ä¸“åˆ©Agent."""
        try:
            # è·å–Agentè·¯ç”±å™¨
            if not self.agent_router:
                # åŠ¨æ€å¯¼å…¥ä»¥é¿å…å¾ªç¯ä¾èµ–
                from ...services.agent_router import AgentRouter
                from ...services.intent_analyzer import IntentAnalyzer
                from ...agents.registry import agent_registry
                from ...config.config_manager import ConfigManager
                
                config_manager = ConfigManager()
                intent_analyzer = IntentAnalyzer(config_manager)
                self.agent_router = AgentRouter(intent_analyzer, agent_registry)
            
            # æ˜ å°„agent_idåˆ°AgentType
            agent_type_mapping = {
                "patent_data_collection_agent": AgentType.PATENT_DATA_COLLECTION,
                "patent_search_agent": AgentType.PATENT_SEARCH,
                "patent_analysis_agent": AgentType.PATENT_ANALYSIS,
                "patent_report_agent": AgentType.PATENT_REPORT,
                "patent_coordinator_agent": AgentType.PATENT_COORDINATOR
            }
            
            agent_type = agent_type_mapping.get(agent_id)
            if not agent_type:
                raise ValueError(f"Unknown patent agent ID: {agent_id}")
            
            # è·å–Agentå®ä¾‹
            from ...agents.registry import agent_registry
            agents = agent_registry.get_agents_by_type(agent_type)
            
            if not agents:
                raise RuntimeError(f"No agents found for type: {agent_type}")
            
            # é€‰æ‹©æœ€ä½³Agentå®ä¾‹ï¼ˆè´Ÿè½½æœ€ä½çš„å¥åº·Agentï¼‰
            best_agent = None
            min_load = float('inf')
            
            for agent in agents:
                try:
                    if agent.is_healthy():
                        agent_info = agent.get_status()
                        load_ratio = agent_info.current_load / max(agent_info.max_load, 1)
                        if load_ratio < min_load:
                            min_load = load_ratio
                            best_agent = agent
                except Exception as e:
                    self.logger.warning(f"Error checking agent {agent.agent_id} status: {str(e)}")
                    continue
            
            if not best_agent:
                raise RuntimeError(f"No healthy agents available for type: {agent_type}")
            
            # è°ƒç”¨Agent
            self.logger.info(f"Calling patent agent {best_agent.agent_id} for request {request.request_id}")
            response = await best_agent.process_request(request)
            
            if not response:
                raise RuntimeError(f"Agent {best_agent.agent_id} returned no response")
            
            # æ·»åŠ è°ƒç”¨å…ƒæ•°æ®
            if not response.metadata:
                response.metadata = {}
            
            response.metadata.update({
                "called_by": self.agent_id,
                "call_timestamp": datetime.now().isoformat(),
                "agent_load": min_load,
                "coordination_context": True
            })
            
            return response
            
        except Exception as e:
            self.logger.error(f"Error calling patent agent {agent_id}: {str(e)}")
            return self._create_error_response(agent_id, f"Agent call failed: {str(e)}")
    
    def _create_error_response(self, agent_id: str, error_message: str) -> AgentResponse:
        """åˆ›å»ºé”™è¯¯å“åº”."""
        return AgentResponse(
            agent_id=agent_id,
            agent_type=AgentType.PATENT_COORDINATOR,
            response_content=f"âŒ **Agentè°ƒç”¨å¤±è´¥**\n\n**Agent**: {agent_id}\n**é”™è¯¯**: {error_message}\n\nè¯·æ£€æŸ¥AgentçŠ¶æ€æˆ–ç¨åé‡è¯•ã€‚",
            confidence=0.0,
            collaboration_needed=False,
            metadata={
                "error": True,
                "error_message": error_message,
                "failed_agent": agent_id,
                "timestamp": datetime.now().isoformat()
            }
        )

    async def _call_patent_agent_with_retry(self, agent_id: str, request: UserRequest, 
                                          max_retries: int = 3, retry_delay: float = 1.0) -> AgentResponse:
        """å¸¦é‡è¯•æœºåˆ¶çš„Agentè°ƒç”¨."""
        last_error = None
        
        for attempt in range(max_retries):
            try:
                self.logger.info(f"Calling {agent_id}, attempt {attempt + 1}/{max_retries}")
                response = await self._call_patent_agent(agent_id, request)
                
                # æ£€æŸ¥å“åº”è´¨é‡
                if response.confidence > 0.0:  # æˆåŠŸå“åº”
                    if attempt > 0:
                        self.logger.info(f"Agent {agent_id} succeeded on attempt {attempt + 1}")
                    return response
                else:
                    # ç½®ä¿¡åº¦ä¸º0è¡¨ç¤ºå¤±è´¥ï¼Œä½†ä¸æ˜¯å¼‚å¸¸
                    last_error = f"Agent returned low confidence response: {response.response_content}"
                    
            except Exception as e:
                last_error = str(e)
                self.logger.warning(f"Agent {agent_id} call failed on attempt {attempt + 1}: {last_error}")
                
                # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…åé‡è¯•
                if attempt < max_retries - 1:
                    await asyncio.sleep(retry_delay * (2 ** attempt))  # æŒ‡æ•°é€€é¿
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
        self.logger.error(f"All retry attempts failed for agent {agent_id}: {last_error}")
        return self._create_error_response(
            agent_id, 
            f"Agent call failed after {max_retries} attempts. Last error: {last_error}"
        )
    
    async def _call_patent_agent_with_fallback(self, agent_id: str, request: UserRequest) -> AgentResponse:
        """å¸¦é™çº§ç­–ç•¥çš„Agentè°ƒç”¨."""
        try:
            # é¦–å…ˆå°è¯•æ­£å¸¸è°ƒç”¨
            response = await self._call_patent_agent_with_retry(agent_id, request)
            
            # å¦‚æœå“åº”è´¨é‡å¯æ¥å—ï¼Œç›´æ¥è¿”å›
            if response.confidence >= 0.3:
                return response
            
            # å¦‚æœå“åº”è´¨é‡å¤ªä½ï¼Œå°è¯•é™çº§ç­–ç•¥
            self.logger.warning(f"Agent {agent_id} response quality too low, trying fallback strategies")
            
            # é™çº§ç­–ç•¥1ï¼šå°è¯•è°ƒç”¨åŒç±»å‹çš„å…¶ä»–Agent
            fallback_response = await self._try_alternative_agents(agent_id, request)
            if fallback_response and fallback_response.confidence >= 0.3:
                return fallback_response
            
            # é™çº§ç­–ç•¥2ï¼šä½¿ç”¨ç®€åŒ–çš„å¤„ç†é€»è¾‘
            return await self._create_simplified_response(agent_id, request)
            
        except Exception as e:
            self.logger.error(f"Fallback strategy failed for {agent_id}: {str(e)}")
            return self._create_error_response(agent_id, f"All fallback strategies failed: {str(e)}")
    
    async def _try_alternative_agents(self, failed_agent_id: str, request: UserRequest) -> Optional[AgentResponse]:
        """å°è¯•è°ƒç”¨åŒç±»å‹çš„å…¶ä»–Agent."""
        try:
            from ...agents.registry import agent_registry
            
            # è·å–å¤±è´¥Agentçš„ç±»å‹
            agent_type_mapping = {
                "patent_data_collection_agent": AgentType.PATENT_DATA_COLLECTION,
                "patent_search_agent": AgentType.PATENT_SEARCH,
                "patent_analysis_agent": AgentType.PATENT_ANALYSIS,
                "patent_report_agent": AgentType.PATENT_REPORT
            }
            
            agent_type = agent_type_mapping.get(failed_agent_id)
            if not agent_type:
                return None
            
            # è·å–åŒç±»å‹çš„æ‰€æœ‰Agent
            agents = agent_registry.get_agents_by_type(agent_type)
            
            # å°è¯•å…¶ä»–å¥åº·çš„Agent
            for agent in agents:
                if agent.agent_id != failed_agent_id and agent.is_healthy():
                    self.logger.info(f"Trying alternative agent: {agent.agent_id}")
                    try:
                        response = await agent.process_request(request)
                        if response and response.confidence > 0.0:
                            # æ ‡è®°è¿™æ˜¯æ›¿ä»£Agentçš„å“åº”
                            if not response.metadata:
                                response.metadata = {}
                            response.metadata.update({
                                "alternative_agent": True,
                                "original_agent": failed_agent_id,
                                "fallback_reason": "primary_agent_failed"
                            })
                            return response
                    except Exception as e:
                        self.logger.warning(f"Alternative agent {agent.agent_id} also failed: {str(e)}")
                        continue
            
            return None
            
        except Exception as e:
            self.logger.error(f"Error trying alternative agents: {str(e)}")
            return None
    
    async def _create_simplified_response(self, agent_id: str, request: UserRequest) -> AgentResponse:
        """åˆ›å»ºç®€åŒ–çš„å“åº”ï¼ˆæœ€åçš„é™çº§ç­–ç•¥ï¼‰."""
        capabilities = self.patent_agent_capabilities.get(agent_id, ["é€šç”¨å¤„ç†"])
        
        # åŸºäºAgentç±»å‹ç”Ÿæˆç®€åŒ–å“åº”
        if "data_collection" in agent_id:
            content = self._generate_simplified_data_collection_response(request)
        elif "search" in agent_id:
            content = self._generate_simplified_search_response(request)
        elif "analysis" in agent_id:
            content = self._generate_simplified_analysis_response(request)
        elif "report" in agent_id:
            content = self._generate_simplified_report_response(request)
        else:
            content = f"å·²æ”¶åˆ°ä¸“åˆ©ç›¸å…³è¯·æ±‚ï¼Œä½† {agent_id} å½“å‰ä¸å¯ç”¨ã€‚è¯·ç¨åé‡è¯•ã€‚"
        
        return AgentResponse(
            agent_id=agent_id,
            agent_type=AgentType.PATENT_COORDINATOR,
            response_content=content,
            confidence=0.4,  # ç®€åŒ–å“åº”æœ‰ä¸€å®šç½®ä¿¡åº¦
            collaboration_needed=True,
            metadata={
                "simplified_response": True,
                "reason": "agent_unavailable_fallback",
                "capabilities": capabilities,
                "timestamp": datetime.now().isoformat()
            }
        )
    
    def _generate_simplified_data_collection_response(self, request: UserRequest) -> str:
        """ç”Ÿæˆç®€åŒ–çš„æ•°æ®æ”¶é›†å“åº”."""
        return """ğŸ“Š **ä¸“åˆ©æ•°æ®æ”¶é›† - ç®€åŒ–å“åº”**

âš ï¸ ä¸“åˆ©æ•°æ®æ”¶é›†Agentå½“å‰ä¸å¯ç”¨ï¼Œä»¥ä¸‹æ˜¯åŸºç¡€å¤„ç†ç»“æœï¼š

**å¤„ç†çŠ¶æ€**: å·²æ¥æ”¶è¯·æ±‚
**å»ºè®®æ“ä½œ**: 
- è¯·ç¨åé‡è¯•å®Œæ•´çš„æ•°æ®æ”¶é›†åŠŸèƒ½
- æˆ–æ‰‹åŠ¨è®¿é—®ä¸“åˆ©æ•°æ®åº“è¿›è¡ŒæŸ¥è¯¢
- è”ç³»æŠ€æœ¯æ”¯æŒè·å–å¸®åŠ©

**ä¸´æ—¶æ–¹æ¡ˆ**: å¯ä»¥ä½¿ç”¨å…¬å¼€çš„ä¸“åˆ©æ£€ç´¢ç½‘ç«™è¿›è¡Œåˆæ­¥æŸ¥è¯¢ã€‚"""
    
    def _generate_simplified_search_response(self, request: UserRequest) -> str:
        """ç”Ÿæˆç®€åŒ–çš„æœç´¢å“åº”."""
        return """ğŸ” **ä¸“åˆ©æœç´¢ - ç®€åŒ–å“åº”**

âš ï¸ ä¸“åˆ©æœç´¢Agentå½“å‰ä¸å¯ç”¨ï¼Œä»¥ä¸‹æ˜¯åŸºç¡€å¤„ç†ç»“æœï¼š

**å¤„ç†çŠ¶æ€**: å·²æ¥æ”¶æœç´¢è¯·æ±‚
**å»ºè®®æ“ä½œ**: 
- è¯·ç¨åé‡è¯•å®Œæ•´çš„æœç´¢åŠŸèƒ½
- æˆ–ä½¿ç”¨CNKIã€Google Patentsç­‰å¹³å°æ‰‹åŠ¨æœç´¢
- è”ç³»æŠ€æœ¯æ”¯æŒè·å–å¸®åŠ©

**ä¸´æ—¶æ–¹æ¡ˆ**: å»ºè®®ç›´æ¥è®¿é—®ç›¸å…³ä¸“åˆ©æ•°æ®åº“è¿›è¡ŒæŸ¥è¯¢ã€‚"""
    
    def _generate_simplified_analysis_response(self, request: UserRequest) -> str:
        """ç”Ÿæˆç®€åŒ–çš„åˆ†æå“åº”."""
        return """ğŸ“ˆ **ä¸“åˆ©åˆ†æ - ç®€åŒ–å“åº”**

âš ï¸ ä¸“åˆ©åˆ†æAgentå½“å‰ä¸å¯ç”¨ï¼Œä»¥ä¸‹æ˜¯åŸºç¡€å¤„ç†ç»“æœï¼š

**å¤„ç†çŠ¶æ€**: å·²æ¥æ”¶åˆ†æè¯·æ±‚
**å»ºè®®æ“ä½œ**: 
- è¯·ç¨åé‡è¯•å®Œæ•´çš„åˆ†æåŠŸèƒ½
- æˆ–ä½¿ç”¨ä¸“ä¸šçš„ä¸“åˆ©åˆ†æå·¥å…·
- è”ç³»æŠ€æœ¯æ”¯æŒè·å–å¸®åŠ©

**ä¸´æ—¶æ–¹æ¡ˆ**: å¯ä»¥è¿›è¡ŒåŸºç¡€çš„ä¸“åˆ©ç»Ÿè®¡å’Œè¶‹åŠ¿è§‚å¯Ÿã€‚"""
    
    def _generate_simplified_report_response(self, request: UserRequest) -> str:
        """ç”Ÿæˆç®€åŒ–çš„æŠ¥å‘Šå“åº”."""
        return """ğŸ“‹ **ä¸“åˆ©æŠ¥å‘Š - ç®€åŒ–å“åº”**

âš ï¸ ä¸“åˆ©æŠ¥å‘ŠAgentå½“å‰ä¸å¯ç”¨ï¼Œä»¥ä¸‹æ˜¯åŸºç¡€å¤„ç†ç»“æœï¼š

**å¤„ç†çŠ¶æ€**: å·²æ¥æ”¶æŠ¥å‘Šè¯·æ±‚
**å»ºè®®æ“ä½œ**: 
- è¯·ç¨åé‡è¯•å®Œæ•´çš„æŠ¥å‘Šç”ŸæˆåŠŸèƒ½
- æˆ–ä½¿ç”¨ç°æœ‰æ¨¡æ¿æ‰‹åŠ¨åˆ›å»ºæŠ¥å‘Š
- è”ç³»æŠ€æœ¯æ”¯æŒè·å–å¸®åŠ©

**ä¸´æ—¶æ–¹æ¡ˆ**: å¯ä»¥å¯¼å‡ºåŸºç¡€æ•°æ®è¿›è¡Œæ‰‹åŠ¨æŠ¥å‘Šåˆ¶ä½œã€‚"""
    
    async def _call_patent_agent(self, agent_id: str, request: UserRequest) -> AgentResponse:
        """è°ƒç”¨ä¸“åˆ©Agentï¼ˆçœŸå®å®ç°ï¼Œé€šè¿‡AgentRegistryè·å–Agentå®ä¾‹ï¼‰."""
        try:
            # è·å–Agentæ³¨å†Œå™¨
            from ...agents.registry import agent_registry
            
            # æ ¹æ®agent_idæ˜ å°„åˆ°å®é™…çš„Agentç±»å‹å’Œå®ä¾‹
            agent_type_mapping = {
                "patent_data_collection_agent": AgentType.PATENT_DATA_COLLECTION,
                "patent_search_agent": AgentType.PATENT_SEARCH,
                "patent_analysis_agent": AgentType.PATENT_ANALYSIS,
                "patent_report_agent": AgentType.PATENT_REPORT
            }
            
            agent_type = agent_type_mapping.get(agent_id)
            if not agent_type:
                self.logger.error(f"Unknown patent agent ID: {agent_id}")
                return self._create_error_response(agent_id, f"Unknown agent ID: {agent_id}")
            
            # å°è¯•è·å–Agentå®ä¾‹
            agents = agent_registry.get_agents_by_type(agent_type)
            if not agents:
                self.logger.warning(f"No agents found for type {agent_type.value}, creating fallback response")
                return self._create_fallback_response(agent_id, agent_type, request)
            
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„Agent
            agent = agents[0]
            
            # æ£€æŸ¥AgentçŠ¶æ€
            if not agent.is_healthy():
                self.logger.warning(f"Agent {agent_id} is not healthy, attempting to use anyway")
            
            # è°ƒç”¨Agentå¤„ç†è¯·æ±‚
            self.logger.info(f"Calling real patent agent: {agent_id} (type: {agent_type.value})")
            response = await agent.process_request(request)
            
            # éªŒè¯å“åº”
            if not response:
                return self._create_error_response(agent_id, "Agent returned empty response")
            
            # å¢å¼ºå“åº”å…ƒæ•°æ®
            if not response.metadata:
                response.metadata = {}
            
            response.metadata.update({
                "called_by_coordinator": True,
                "coordinator_id": self.agent_id,
                "real_agent_call": True,
                "agent_type": agent_type.value,
                "call_timestamp": datetime.now().isoformat()
            })
            
            self.logger.info(f"Successfully called patent agent {agent_id}, confidence: {response.confidence}")
            return response
            
        except Exception as e:
            self.logger.error(f"Error calling patent agent {agent_id}: {str(e)}")
            return self._create_error_response(agent_id, str(e))
    
    def _create_error_response(self, agent_id: str, error_message: str) -> AgentResponse:
        """åˆ›å»ºé”™è¯¯å“åº”."""
        return AgentResponse(
            agent_id=agent_id,
            agent_type=AgentType.PATENT_COORDINATOR,
            response_content=f"è°ƒç”¨ {agent_id} æ—¶å‘ç”Ÿé”™è¯¯: {error_message}",
            confidence=0.0,
            collaboration_needed=False,
            metadata={
                "error": error_message,
                "error_type": "agent_call_failure",
                "timestamp": datetime.now().isoformat()
            }
        )
    
    def _create_fallback_response(self, agent_id: str, agent_type: AgentType, request: UserRequest) -> AgentResponse:
        """åˆ›å»ºé™çº§å“åº”ï¼ˆå½“çœŸå®Agentä¸å¯ç”¨æ—¶ï¼‰."""
        capabilities = self.patent_agent_capabilities.get(agent_id, ["é€šç”¨å¤„ç†"])
        
        fallback_content = f"ğŸ“‹ **{agent_id} é™çº§å“åº”**\n\n"
        fallback_content += f"**Agentç±»å‹**: {agent_type.value}\n"
        fallback_content += f"**å¤„ç†èƒ½åŠ›**: {', '.join(capabilities)}\n"
        fallback_content += f"**è¯·æ±‚å†…å®¹**: {request.content[:100]}...\n\n"
        fallback_content += "âš ï¸ **æ³¨æ„**: ç”±äºçœŸå®Agentä¸å¯ç”¨ï¼Œè¿™æ˜¯ä¸€ä¸ªé™çº§å“åº”ã€‚\n"
        fallback_content += "ç³»ç»Ÿå·²è®°å½•æ­¤é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•æˆ–è”ç³»æŠ€æœ¯æ”¯æŒã€‚\n\n"
        fallback_content += f"**å»ºè®®**: æ£€æŸ¥ {agent_type.value} çš„æ³¨å†ŒçŠ¶æ€å’Œå¥åº·çŠ¶å†µã€‚"
        
        return AgentResponse(
            agent_id=agent_id,
            agent_type=agent_type,
            response_content=fallback_content,
            confidence=0.3,  # é™çº§å“åº”çš„ç½®ä¿¡åº¦è¾ƒä½
            collaboration_needed=True,  # å¯èƒ½éœ€è¦äººå·¥å¹²é¢„
            metadata={
                "fallback_response": True,
                "reason": "real_agent_unavailable",
                "agent_type": agent_type.value,
                "capabilities": capabilities,
                "timestamp": datetime.now().isoformat(),
                "shared_data": {
                    f"{agent_id}_status": "unavailable",
                    f"{agent_id}_fallback": True
                }
            }
        )
    
    def _integrate_sequential_patent_results(self, results: List[AgentResponse], 
                                           workflow_context: Dict[str, Any]) -> str:
        """æ•´åˆé¡ºåºä¸“åˆ©æ‰§è¡Œç»“æœ."""
        task_type = workflow_context.get("task_type", "comprehensive_analysis")
        
        result = f"ğŸ”¬ **ä¸“åˆ©{self.patent_workflow_types.get(task_type, 'åˆ†æ')}å®Œæˆ** ğŸ”¬\n\n"
        result += f"**æ‰§è¡Œæ¨¡å¼ï¼š** é¡ºåºæ‰§è¡Œ\n"
        result += f"**ä»»åŠ¡ç±»å‹ï¼š** {task_type}\n\n"
        
        result += "**æ‰§è¡Œæµç¨‹ï¼š**\n"
        for i, response in enumerate(results, 1):
            result += f"{i}. **{response.agent_id}**ï¼š{response.response_content[:100]}...\n"
        
        result += "\n**åè°ƒæ€»ç»“ï¼š**\n"
        result += "å„é˜¶æ®µä¸“åˆ©åˆ†æå·²æŒ‰é¡ºåºå®Œæˆï¼Œæ•°æ®å·²åœ¨å„Agenté—´æœ‰æ•ˆä¼ é€’å’Œç´¯ç§¯ã€‚"
        
        return result
    
    def _integrate_parallel_patent_results(self, results: List[AgentResponse], 
                                         workflow_context: Dict[str, Any]) -> str:
        """æ•´åˆå¹¶è¡Œä¸“åˆ©æ‰§è¡Œç»“æœ."""
        task_type = workflow_context.get("task_type", "comprehensive_analysis")
        
        result = f"ğŸ”¬ **ä¸“åˆ©{self.patent_workflow_types.get(task_type, 'åˆ†æ')}å®Œæˆ** ğŸ”¬\n\n"
        result += f"**æ‰§è¡Œæ¨¡å¼ï¼š** å¹¶è¡Œæ‰§è¡Œ\n"
        result += f"**ä»»åŠ¡ç±»å‹ï¼š** {task_type}\n\n"
        
        result += "**å¹¶è¡Œå¤„ç†ç»“æœï¼š**\n"
        for response in results:
            result += f"â€¢ **{response.agent_id}**ï¼š{response.response_content[:100]}...\n"
        
        result += "\n**åè°ƒæ€»ç»“ï¼š**\n"
        result += "å¤šä¸ªä¸“åˆ©Agentå¹¶è¡Œå¤„ç†ï¼Œæ˜¾è‘—æå‡äº†åˆ†ææ•ˆç‡ï¼Œç»“æœå·²æ•´åˆå®Œæˆã€‚"
        
        return result
    
    def _integrate_hierarchical_patent_results(self, results: List[AgentResponse], 
                                             workflow_context: Dict[str, Any]) -> str:
        """æ•´åˆåˆ†å±‚ä¸“åˆ©æ‰§è¡Œç»“æœ."""
        task_type = workflow_context.get("task_type", "comprehensive_analysis")
        
        result = f"ğŸ”¬ **ä¸“åˆ©{self.patent_workflow_types.get(task_type, 'åˆ†æ')}å®Œæˆ** ğŸ”¬\n\n"
        result += f"**æ‰§è¡Œæ¨¡å¼ï¼š** åˆ†å±‚åè°ƒ\n"
        result += f"**ä»»åŠ¡ç±»å‹ï¼š** {task_type}\n\n"
        
        result += "**åˆ†å±‚æ‰§è¡Œæ¶æ„ï¼š**\n"
        result += "1. **æ•°æ®å±‚**ï¼šä¸“åˆ©æ•°æ®æ”¶é›†å’Œæœç´¢å¢å¼º\n"
        result += "2. **åˆ†æå±‚**ï¼šæ·±åº¦åˆ†æå’Œæ¨¡å¼è¯†åˆ«\n"
        result += "3. **å±•ç¤ºå±‚**ï¼šæŠ¥å‘Šç”Ÿæˆå’Œç»“æœå‘ˆç°\n\n"
        
        result += "**å„å±‚å¤„ç†ç»“æœï¼š**\n"
        for response in results:
            result += f"â€¢ **{response.agent_id}**ï¼š{response.response_content[:80]}...\n"
        
        result += "\n**åè°ƒæ€»ç»“ï¼š**\n"
        result += "é‡‡ç”¨åˆ†å±‚æ¶æ„ç¡®ä¿äº†ä¸“åˆ©åˆ†æçš„ç³»ç»Ÿæ€§å’Œå®Œæ•´æ€§ï¼Œå„å±‚åè°ƒæœ‰åºã€‚"
        
        return result
    
    def _integrate_hybrid_patent_results(self, results: List[AgentResponse], 
                                       workflow_context: Dict[str, Any]) -> str:
        """æ•´åˆæ··åˆä¸“åˆ©æ‰§è¡Œç»“æœ."""
        task_type = workflow_context.get("task_type", "comprehensive_analysis")
        
        result = f"ğŸ”¬ **ä¸“åˆ©{self.patent_workflow_types.get(task_type, 'åˆ†æ')}å®Œæˆ** ğŸ”¬\n\n"
        result += f"**æ‰§è¡Œæ¨¡å¼ï¼š** æ··åˆæ‰§è¡Œ\n"
        result += f"**ä»»åŠ¡ç±»å‹ï¼š** {task_type}\n\n"
        
        result += "**æ··åˆæ‰§è¡Œç­–ç•¥ï¼š**\n"
        result += "â€¢ æ•°æ®æ”¶é›†å’Œæœç´¢ï¼šå¹¶è¡Œæ‰§è¡Œï¼Œæå‡æ•ˆç‡\n"
        result += "â€¢ åˆ†æå’ŒæŠ¥å‘Šï¼šé¡ºåºæ‰§è¡Œï¼Œç¡®ä¿è´¨é‡\n\n"
        
        result += "**å¤„ç†ç»“æœï¼š**\n"
        for response in results:
            result += f"â€¢ **{response.agent_id}**ï¼š{response.response_content[:80]}...\n"
        
        result += "\n**åè°ƒæ€»ç»“ï¼š**\n"
        result += "æ··åˆæ‰§è¡Œç­–ç•¥å…¼é¡¾äº†æ•ˆç‡å’Œè´¨é‡ï¼Œå®ç°äº†æœ€ä¼˜çš„ä¸“åˆ©åˆ†ææµç¨‹ã€‚"
        
        return result
    
    def _extract_shared_data_from_results(self, results: List[AgentResponse]) -> Dict[str, Any]:
        """ä»Agentç»“æœä¸­æå–å…±äº«æ•°æ®."""
        shared_data = {}
        
        for result in results:
            if hasattr(result, 'metadata') and result.metadata:
                shared_data.update(result.metadata.get("shared_data", {}))
        
        return shared_data
    
    async def _generate_patent_coordination_response(self, coordination_result: CollaborationResult,
                                                   workflow_context: Dict[str, Any]) -> str:
        """ç”Ÿæˆä¸“åˆ©åè°ƒå“åº”."""
        task_type = workflow_context.get("task_type", "comprehensive_analysis")
        execution_strategy = workflow_context.get("execution_strategy", "sequential")
        
        response = f"ğŸ¤ **ä¸“åˆ©åˆ†æåè°ƒå®Œæˆ** ğŸ¤\n\n"
        response += f"**åè°ƒæ¨¡å¼ï¼š** {execution_strategy.upper()}\n"
        response += f"**ä»»åŠ¡ç±»å‹ï¼š** {self.patent_workflow_types.get(task_type, task_type)}\n"
        response += f"**å‚ä¸Agentï¼š** {', '.join(coordination_result.participating_agents)}\n"
        response += f"**åè°ƒIDï¼š** {coordination_result.collaboration_id}\n\n"
        
        response += "**åè°ƒç»“æœï¼š**\n"
        response += coordination_result.final_result
        
        if coordination_result.consensus_reached:
            response += "\n\nâœ… **åè°ƒçŠ¶æ€ï¼š** ä¸“åˆ©åˆ†æåè°ƒæˆåŠŸå®Œæˆ"
        else:
            response += "\n\nâš ï¸ **åè°ƒçŠ¶æ€ï¼š** éƒ¨åˆ†Agentæ‰§è¡Œå¼‚å¸¸ï¼Œéœ€è¦äººå·¥æ£€æŸ¥"
        
        response += f"\n\n**è§£å†³æ–¹æ³•ï¼š** {coordination_result.resolution_method}"
        
        # æ·»åŠ ä¸“åˆ©åˆ†æç‰¹å®šçš„æ€»ç»“
        response += "\n\n**ä¸“åˆ©åˆ†ææ€»ç»“ï¼š**\n"
        response += "â€¢ æ•°æ®æ”¶é›†ï¼šâœ… å®Œæˆ\n"
        response += "â€¢ æœç´¢å¢å¼ºï¼šâœ… å®Œæˆ\n" 
        response += "â€¢ æ·±åº¦åˆ†æï¼šâœ… å®Œæˆ\n"
        response += "â€¢ æŠ¥å‘Šç”Ÿæˆï¼šâœ… å®Œæˆ\n"
        
        return response
    
    def _generate_patent_coordination_actions(self, coordination_result: CollaborationResult,
                                            workflow_context: Dict[str, Any]) -> List[Action]:
        """ç”Ÿæˆä¸“åˆ©åè°ƒç›¸å…³çš„åç»­åŠ¨ä½œ."""
        actions = []
        
        # ä¸“åˆ©åˆ†æç›‘æ§
        actions.append(
            Action(
                action_type="monitor_patent_analysis",
                parameters={
                    "coordination_id": coordination_result.collaboration_id,
                    "task_type": workflow_context.get("task_type"),
                    "check_interval": "30_minutes"
                },
                description="ç›‘æ§ä¸“åˆ©åˆ†ææ‰§è¡ŒçŠ¶æ€"
            )
        )
        
        # ç»“æœè´¨é‡éªŒè¯
        actions.append(
            Action(
                action_type="validate_patent_results",
                parameters={
                    "validation_method": "cross_validation",
                    "quality_threshold": 0.8,
                    "timeline": "1_hour"
                },
                description="éªŒè¯ä¸“åˆ©åˆ†æç»“æœè´¨é‡"
            )
        )
        
        # å¦‚æœæœªè¾¾æˆå…±è¯†ï¼Œæ·»åŠ ä¸“åˆ©åˆ†æä¿®å¤åŠ¨ä½œ
        if not coordination_result.consensus_reached:
            actions.append(
                Action(
                    action_type="repair_patent_analysis",
                    parameters={
                        "repair_strategy": "retry_failed_agents",
                        "max_retries": 2
                    },
                    description="ä¿®å¤å¤±è´¥çš„ä¸“åˆ©åˆ†ææ­¥éª¤"
                )
            )
        
        # ä¸“åˆ©æ•°æ®ç¼“å­˜
        actions.append(
            Action(
                action_type="cache_patent_data",
                parameters={
                    "cache_duration": "24_hours",
                    "cache_key": f"patent_analysis_{coordination_result.collaboration_id}"
                },
                description="ç¼“å­˜ä¸“åˆ©åˆ†ææ•°æ®"
            )
        )
        
        return actions
    
    def _estimate_task_duration(self, task_type: str, complexity_level: str) -> int:
        """ä¼°ç®—ä»»åŠ¡æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰."""
        base_times = {
            "quick_search": 60,
            "trend_analysis": 120,
            "competitive_analysis": 180,
            "report_generation": 90,
            "comprehensive_analysis": 240
        }
        
        complexity_multipliers = {
            "low": 0.8,
            "medium": 1.0,
            "high": 1.5
        }
        
        base_time = base_times.get(task_type, 120)
        multiplier = complexity_multipliers.get(complexity_level, 1.0)
        
        return int(base_time * multiplier)
    
    # ä¸“åˆ©åè°ƒAgentç‰¹æœ‰çš„ç®¡ç†æ–¹æ³•
    def get_active_patent_tasks(self) -> Dict[str, Dict[str, Any]]:
        """è·å–å½“å‰æ´»è·ƒçš„ä¸“åˆ©ä»»åŠ¡."""
        return self.active_patent_tasks.copy()
    
    async def terminate_patent_task(self, workflow_id: str) -> bool:
        """ç»ˆæ­¢æŒ‡å®šçš„ä¸“åˆ©ä»»åŠ¡."""
        if workflow_id in self.active_patent_tasks:
            self.active_patent_tasks[workflow_id]["status"] = "terminated"
            self.active_patent_tasks[workflow_id]["end_time"] = datetime.now()
            self.logger.info(f"Terminated patent task {workflow_id}")
            return True
        return False
    
    def get_patent_task_statistics(self) -> Dict[str, Any]:
        """è·å–ä¸“åˆ©ä»»åŠ¡ç»Ÿè®¡ä¿¡æ¯."""
        return {
            "active_tasks": len(self.active_patent_tasks),
            "supported_task_types": list(self.patent_workflow_types.keys()),
            "supported_strategies": list(self.execution_strategies.keys()),
            "agent_capabilities": self.patent_agent_capabilities,
            "last_updated": datetime.now().isoformat()
        }   
 
    async def _synchronize_agent_data(self, workflow_context: Dict[str, Any], 
                                    agent_results: List[AgentResponse]) -> Dict[str, Any]:
        """åŒæ­¥Agenté—´çš„æ•°æ®çŠ¶æ€."""
        try:
            synchronized_data = workflow_context.get("shared_data", {}).copy()
            
            # æ”¶é›†æ‰€æœ‰Agentçš„å…±äº«æ•°æ®
            for result in agent_results:
                if result.metadata and "shared_data" in result.metadata:
                    shared_data = result.metadata["shared_data"]
                    if isinstance(shared_data, dict):
                        synchronized_data.update(shared_data)
                
                # æå–å…³é”®ä¿¡æ¯ç”¨äºåç»­Agent
                if result.confidence > 0.5:  # åªåŒæ­¥é«˜è´¨é‡çš„ç»“æœ
                    agent_key = f"{result.agent_id}_result"
                    synchronized_data[agent_key] = {
                        "content": result.response_content[:500],  # é™åˆ¶é•¿åº¦
                        "confidence": result.confidence,
                        "timestamp": datetime.now().isoformat(),
                        "metadata": result.metadata
                    }
            
            # æ›´æ–°å·¥ä½œæµä¸Šä¸‹æ–‡
            workflow_context["shared_data"] = synchronized_data
            
            # è®°å½•åŒæ­¥çŠ¶æ€
            sync_info = {
                "synchronized_at": datetime.now().isoformat(),
                "data_keys": list(synchronized_data.keys()),
                "agent_count": len(agent_results),
                "high_quality_results": len([r for r in agent_results if r.confidence > 0.5])
            }
            
            workflow_context["sync_info"] = sync_info
            
            self.logger.info(f"Synchronized data from {len(agent_results)} agents, "
                           f"{len(synchronized_data)} data keys")
            
            return synchronized_data
            
        except Exception as e:
            self.logger.error(f"Error synchronizing agent data: {str(e)}")
            return workflow_context.get("shared_data", {})
    
    async def _validate_agent_responses(self, agent_results: List[AgentResponse]) -> Dict[str, Any]:
        """éªŒè¯Agentå“åº”çš„ä¸€è‡´æ€§å’Œè´¨é‡."""
        validation_result = {
            "is_valid": True,
            "quality_score": 0.0,
            "consistency_score": 0.0,
            "issues": [],
            "recommendations": []
        }
        
        try:
            if not agent_results:
                validation_result["is_valid"] = False
                validation_result["issues"].append("No agent responses to validate")
                return validation_result
            
            # è´¨é‡è¯„ä¼°
            confidences = [r.confidence for r in agent_results if r.confidence is not None]
            if confidences:
                validation_result["quality_score"] = sum(confidences) / len(confidences)
            
            # ä¸€è‡´æ€§æ£€æŸ¥
            successful_responses = [r for r in agent_results if r.confidence > 0.3]
            if len(successful_responses) > 1:
                # ç®€å•çš„ä¸€è‡´æ€§æ£€æŸ¥ï¼šæ£€æŸ¥æ˜¯å¦æœ‰ç›¸ä¼¼çš„å…³é”®è¯
                contents = [r.response_content.lower() for r in successful_responses]
                common_words = set()
                for content in contents:
                    words = set(content.split())
                    if not common_words:
                        common_words = words
                    else:
                        common_words &= words
                
                consistency_ratio = len(common_words) / max(len(content.split()) for content in contents)
                validation_result["consistency_score"] = min(consistency_ratio * 2, 1.0)  # å½’ä¸€åŒ–
            
            # ç”Ÿæˆé—®é¢˜å’Œå»ºè®®
            low_quality_count = len([r for r in agent_results if r.confidence < 0.3])
            if low_quality_count > 0:
                validation_result["issues"].append(f"{low_quality_count} agents returned low quality responses")
                validation_result["recommendations"].append("Consider retrying failed agents or adjusting parameters")
            
            failed_count = len([r for r in agent_results if r.confidence == 0.0])
            if failed_count > 0:
                validation_result["issues"].append(f"{failed_count} agents failed completely")
                validation_result["recommendations"].append("Check agent health and system resources")
            
            # ç»¼åˆè¯„ä¼°
            if validation_result["quality_score"] < 0.5:
                validation_result["is_valid"] = False
                validation_result["issues"].append("Overall quality score too low")
            
            return validation_result
            
        except Exception as e:
            self.logger.error(f"Error validating agent responses: {str(e)}")
            validation_result["is_valid"] = False
            validation_result["issues"].append(f"Validation error: {str(e)}")
            return validation_result
    
    async def _handle_coordination_failure(self, workflow_context: Dict[str, Any], 
                                         error: Exception) -> CollaborationResult:
        """å¤„ç†åè°ƒå¤±è´¥çš„æƒ…å†µ."""
        workflow_id = workflow_context.get("workflow_id", "unknown")
        required_agents = workflow_context.get("required_agents", [])
        
        self.logger.error(f"Coordination failure in workflow {workflow_id}: {str(error)}")
        
        # å°è¯•æ¢å¤ç­–ç•¥
        recovery_attempts = []
        
        # æ¢å¤ç­–ç•¥1ï¼šæ£€æŸ¥Agentå¥åº·çŠ¶æ€
        try:
            from ...agents.registry import agent_registry
            unhealthy_agents = []
            
            for agent_id in required_agents:
                agent_type_mapping = {
                    "patent_data_collection_agent": AgentType.PATENT_DATA_COLLECTION,
                    "patent_search_agent": AgentType.PATENT_SEARCH,
                    "patent_analysis_agent": AgentType.PATENT_ANALYSIS,
                    "patent_report_agent": AgentType.PATENT_REPORT
                }
                
                agent_type = agent_type_mapping.get(agent_id)
                if agent_type:
                    agents = agent_registry.get_agents_by_type(agent_type)
                    if not agents or not any(agent.is_healthy() for agent in agents):
                        unhealthy_agents.append(agent_id)
            
            if unhealthy_agents:
                recovery_attempts.append(f"Detected unhealthy agents: {', '.join(unhealthy_agents)}")
            
        except Exception as e:
            recovery_attempts.append(f"Health check failed: {str(e)}")
        
        # ç”Ÿæˆå¤±è´¥æŠ¥å‘Š
        failure_report = f"""ğŸš¨ **ä¸“åˆ©åè°ƒå¤±è´¥æŠ¥å‘Š** ğŸš¨

**å·¥ä½œæµID**: {workflow_id}
**å¤±è´¥æ—¶é—´**: {datetime.now().isoformat()}
**é”™è¯¯ä¿¡æ¯**: {str(error)}

**æ¶‰åŠçš„Agent**: {', '.join(required_agents)}

**æ¢å¤å°è¯•**:
{chr(10).join(f"- {attempt}" for attempt in recovery_attempts)}

**å»ºè®®æ“ä½œ**:
- æ£€æŸ¥Agentç³»ç»Ÿå¥åº·çŠ¶æ€
- éªŒè¯ä¸“åˆ©ç³»ç»Ÿåˆå§‹åŒ–çŠ¶æ€
- é‡æ–°æäº¤è¯·æ±‚
- è”ç³»æŠ€æœ¯æ”¯æŒ

**ä¸´æ—¶æ–¹æ¡ˆ**: å¯ä»¥å°è¯•ä½¿ç”¨å•ä¸ªAgentè¿›è¡Œéƒ¨åˆ†å¤„ç†ï¼Œæˆ–æ‰‹åŠ¨æ‰§è¡Œç›¸å…³ä»»åŠ¡ã€‚
"""
        
        return CollaborationResult(
            collaboration_id=workflow_id,
            participating_agents=required_agents + [self.agent_id],
            final_result=failure_report,
            consensus_reached=False,
            resolution_method="failure_handling",
            metadata={
                "failure": True,
                "error": str(error),
                "recovery_attempts": recovery_attempts,
                "failed_at": datetime.now().isoformat()
            }
        )
    
    # ç»“æœæ•´åˆæ–¹æ³•
    def _integrate_sequential_patent_results(self, results: List[AgentResponse], 
                                           workflow_context: Dict[str, Any]) -> str:
        """æ•´åˆé¡ºåºæ‰§è¡Œçš„ä¸“åˆ©åˆ†æç»“æœ."""
        try:
            successful_results = [r for r in results if r.confidence > 0.0]
            
            if not successful_results:
                return "âŒ **ä¸“åˆ©åˆ†æå¤±è´¥**\n\næ‰€æœ‰Agentéƒ½æœªèƒ½æˆåŠŸå¤„ç†è¯·æ±‚ã€‚è¯·æ£€æŸ¥ç³»ç»ŸçŠ¶æ€æˆ–ç¨åé‡è¯•ã€‚"
            
            # æŒ‰Agentç±»å‹ç»„ç»‡ç»“æœ
            organized_results = {}
            for result in successful_results:
                agent_type = self._identify_agent_type_from_id(result.agent_id)
                organized_results[agent_type] = result.response_content
            
            # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
            report_sections = []
            
            if "data_collection" in organized_results:
                report_sections.append(f"## ğŸ“Š æ•°æ®æ”¶é›†ç»“æœ\n{organized_results['data_collection']}")
            
            if "search" in organized_results:
                report_sections.append(f"## ğŸ” æœç´¢å¢å¼ºç»“æœ\n{organized_results['search']}")
            
            if "analysis" in organized_results:
                report_sections.append(f"## ğŸ“ˆ åˆ†æå¤„ç†ç»“æœ\n{organized_results['analysis']}")
            
            if "report" in organized_results:
                report_sections.append(f"## ğŸ“‹ æŠ¥å‘Šç”Ÿæˆç»“æœ\n{organized_results['report']}")
            
            # æ·»åŠ æ‰§è¡Œæ‘˜è¦
            execution_summary = f"""# ğŸ¯ ä¸“åˆ©åˆ†ææ‰§è¡Œæ‘˜è¦

**æ‰§è¡Œæ¨¡å¼**: é¡ºåºæ‰§è¡Œ
**æˆåŠŸAgentæ•°**: {len(successful_results)}/{len(results)}
**æ‰§è¡Œæ—¶é—´**: {workflow_context.get('start_time', 'Unknown')}
**å·¥ä½œæµID**: {workflow_context.get('workflow_id', 'Unknown')}

---

"""
            
            return execution_summary + "\n\n".join(report_sections)
            
        except Exception as e:
            self.logger.error(f"Error integrating sequential results: {str(e)}")
            return f"âŒ **ç»“æœæ•´åˆå¤±è´¥**: {str(e)}"
    
    def _integrate_parallel_patent_results(self, results: List[AgentResponse], 
                                         workflow_context: Dict[str, Any]) -> str:
        """æ•´åˆå¹¶è¡Œæ‰§è¡Œçš„ä¸“åˆ©åˆ†æç»“æœ."""
        try:
            successful_results = [r for r in results if r.confidence > 0.0]
            
            if not successful_results:
                return "âŒ **ä¸“åˆ©åˆ†æå¤±è´¥**\n\næ‰€æœ‰Agentéƒ½æœªèƒ½æˆåŠŸå¤„ç†è¯·æ±‚ã€‚è¯·æ£€æŸ¥ç³»ç»ŸçŠ¶æ€æˆ–ç¨åé‡è¯•ã€‚"
            
            # æŒ‰ç½®ä¿¡åº¦æ’åº
            successful_results.sort(key=lambda x: x.confidence, reverse=True)
            
            # ç”Ÿæˆå¹¶è¡Œæ‰§è¡ŒæŠ¥å‘Š
            report_sections = []
            
            # æ·»åŠ æ‰§è¡Œæ‘˜è¦
            avg_confidence = sum(r.confidence for r in successful_results) / len(successful_results)
            execution_summary = f"""# âš¡ ä¸“åˆ©åˆ†æå¹¶è¡Œæ‰§è¡Œç»“æœ

**æ‰§è¡Œæ¨¡å¼**: å¹¶è¡Œæ‰§è¡Œ
**æˆåŠŸAgentæ•°**: {len(successful_results)}/{len(results)}
**å¹³å‡ç½®ä¿¡åº¦**: {avg_confidence:.2f}
**æ‰§è¡Œæ—¶é—´**: {workflow_context.get('start_time', 'Unknown')}
**å·¥ä½œæµID**: {workflow_context.get('workflow_id', 'Unknown')}

---

"""
            
            # æŒ‰ç½®ä¿¡åº¦å±•ç¤ºç»“æœ
            for i, result in enumerate(successful_results, 1):
                agent_type = self._identify_agent_type_from_id(result.agent_id)
                report_sections.append(f"""## {i}. {agent_type.upper()} (ç½®ä¿¡åº¦: {result.confidence:.2f})

{result.response_content}

---
""")
            
            return execution_summary + "\n".join(report_sections)
            
        except Exception as e:
            self.logger.error(f"Error integrating parallel results: {str(e)}")
            return f"âŒ **ç»“æœæ•´åˆå¤±è´¥**: {str(e)}"
    
    def _integrate_hierarchical_patent_results(self, results: List[AgentResponse], 
                                             workflow_context: Dict[str, Any]) -> str:
        """æ•´åˆåˆ†å±‚æ‰§è¡Œçš„ä¸“åˆ©åˆ†æç»“æœ."""
        try:
            successful_results = [r for r in results if r.confidence > 0.0]
            
            if not successful_results:
                return "âŒ **ä¸“åˆ©åˆ†æå¤±è´¥**\n\næ‰€æœ‰Agentéƒ½æœªèƒ½æˆåŠŸå¤„ç†è¯·æ±‚ã€‚è¯·æ£€æŸ¥ç³»ç»ŸçŠ¶æ€æˆ–ç¨åé‡è¯•ã€‚"
            
            # æŒ‰å±‚çº§ç»„ç»‡ç»“æœ
            layers = {
                "data_layer": [],
                "analysis_layer": [],
                "report_layer": []
            }
            
            for result in successful_results:
                agent_type = self._identify_agent_type_from_id(result.agent_id)
                if agent_type in ["data_collection", "search"]:
                    layers["data_layer"].append(result)
                elif agent_type in ["analysis"]:
                    layers["analysis_layer"].append(result)
                elif agent_type in ["report"]:
                    layers["report_layer"].append(result)
            
            # ç”Ÿæˆåˆ†å±‚æŠ¥å‘Š
            report_sections = []
            
            # æ‰§è¡Œæ‘˜è¦
            execution_summary = f"""# ğŸ—ï¸ ä¸“åˆ©åˆ†æåˆ†å±‚æ‰§è¡Œç»“æœ

**æ‰§è¡Œæ¨¡å¼**: åˆ†å±‚æ‰§è¡Œ
**æˆåŠŸAgentæ•°**: {len(successful_results)}/{len(results)}
**æ‰§è¡Œå±‚çº§**: {len([layer for layer in layers.values() if layer])}å±‚
**å·¥ä½œæµID**: {workflow_context.get('workflow_id', 'Unknown')}

---

"""
            
            # æ•°æ®å±‚ç»“æœ
            if layers["data_layer"]:
                report_sections.append("## ğŸ“Š ç¬¬ä¸€å±‚ï¼šæ•°æ®æ”¶é›†ä¸æœç´¢")
                for result in layers["data_layer"]:
                    agent_type = self._identify_agent_type_from_id(result.agent_id)
                    report_sections.append(f"### {agent_type.upper()}\n{result.response_content}\n")
            
            # åˆ†æå±‚ç»“æœ
            if layers["analysis_layer"]:
                report_sections.append("## ğŸ“ˆ ç¬¬äºŒå±‚ï¼šåˆ†æå¤„ç†")
                for result in layers["analysis_layer"]:
                    report_sections.append(f"{result.response_content}\n")
            
            # æŠ¥å‘Šå±‚ç»“æœ
            if layers["report_layer"]:
                report_sections.append("## ğŸ“‹ ç¬¬ä¸‰å±‚ï¼šæŠ¥å‘Šç”Ÿæˆ")
                for result in layers["report_layer"]:
                    report_sections.append(f"{result.response_content}\n")
            
            return execution_summary + "\n".join(report_sections)
            
        except Exception as e:
            self.logger.error(f"Error integrating hierarchical results: {str(e)}")
            return f"âŒ **ç»“æœæ•´åˆå¤±è´¥**: {str(e)}"
    
    def _integrate_hybrid_patent_results(self, results: List[AgentResponse], 
                                       workflow_context: Dict[str, Any]) -> str:
        """æ•´åˆæ··åˆæ‰§è¡Œçš„ä¸“åˆ©åˆ†æç»“æœ."""
        try:
            successful_results = [r for r in results if r.confidence > 0.0]
            
            if not successful_results:
                return "âŒ **ä¸“åˆ©åˆ†æå¤±è´¥**\n\næ‰€æœ‰Agentéƒ½æœªèƒ½æˆåŠŸå¤„ç†è¯·æ±‚ã€‚è¯·æ£€æŸ¥ç³»ç»ŸçŠ¶æ€æˆ–ç¨åé‡è¯•ã€‚"
            
            # åˆ†ç»„ï¼šå¹¶è¡Œæ‰§è¡Œçš„å’Œé¡ºåºæ‰§è¡Œçš„
            parallel_results = []
            sequential_results = []
            
            for result in successful_results:
                agent_type = self._identify_agent_type_from_id(result.agent_id)
                if agent_type in ["data_collection", "search"]:
                    parallel_results.append(result)
                else:
                    sequential_results.append(result)
            
            # ç”Ÿæˆæ··åˆæ‰§è¡ŒæŠ¥å‘Š
            report_sections = []
            
            # æ‰§è¡Œæ‘˜è¦
            execution_summary = f"""# ğŸ”„ ä¸“åˆ©åˆ†ææ··åˆæ‰§è¡Œç»“æœ

**æ‰§è¡Œæ¨¡å¼**: æ··åˆæ‰§è¡Œï¼ˆå¹¶è¡Œ+é¡ºåºï¼‰
**æˆåŠŸAgentæ•°**: {len(successful_results)}/{len(results)}
**å¹¶è¡Œæ‰§è¡Œ**: {len(parallel_results)}ä¸ªAgent
**é¡ºåºæ‰§è¡Œ**: {len(sequential_results)}ä¸ªAgent
**å·¥ä½œæµID**: {workflow_context.get('workflow_id', 'Unknown')}

---

"""
            
            # å¹¶è¡Œæ‰§è¡Œç»“æœ
            if parallel_results:
                report_sections.append("## âš¡ å¹¶è¡Œæ‰§è¡Œé˜¶æ®µï¼šæ•°æ®æ”¶é›†ä¸æœç´¢")
                for result in parallel_results:
                    agent_type = self._identify_agent_type_from_id(result.agent_id)
                    report_sections.append(f"### {agent_type.upper()}\n{result.response_content}\n")
            
            # é¡ºåºæ‰§è¡Œç»“æœ
            if sequential_results:
                report_sections.append("## ğŸ”„ é¡ºåºæ‰§è¡Œé˜¶æ®µï¼šåˆ†æä¸æŠ¥å‘Š")
                for result in sequential_results:
                    agent_type = self._identify_agent_type_from_id(result.agent_id)
                    report_sections.append(f"### {agent_type.upper()}\n{result.response_content}\n")
            
            return execution_summary + "\n".join(report_sections)
            
        except Exception as e:
            self.logger.error(f"Error integrating hybrid results: {str(e)}")
            return f"âŒ **ç»“æœæ•´åˆå¤±è´¥**: {str(e)}"
    
    def _identify_agent_type_from_id(self, agent_id: str) -> str:
        """ä»Agent IDè¯†åˆ«Agentç±»å‹."""
        if "data_collection" in agent_id:
            return "data_collection"
        elif "search" in agent_id:
            return "search"
        elif "analysis" in agent_id:
            return "analysis"
        elif "report" in agent_id:
            return "report"
        elif "coordinator" in agent_id:
            return "coordinator"
        else:
            return "unknown"
    
    def _extract_shared_data_from_results(self, results: List[AgentResponse]) -> Dict[str, Any]:
        """ä»Agentç»“æœä¸­æå–å…±äº«æ•°æ®."""
        shared_data = {}
        
        try:
            for result in results:
                if result.metadata and "shared_data" in result.metadata:
                    shared_data.update(result.metadata["shared_data"])
                
                # ä»å“åº”å†…å®¹ä¸­æå–ç»“æ„åŒ–æ•°æ®ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                if hasattr(result, 'structured_data'):
                    shared_data.update(result.structured_data)
            
            return shared_data
            
        except Exception as e:
            self.logger.error(f"Error extracting shared data: {str(e)}")
            return {}
    
    async def _synchronize_agent_data(self, workflow_context: Dict[str, Any], 
                                    results: List[AgentResponse]) -> None:
        """åŒæ­¥Agenté—´çš„æ•°æ®."""
        try:
            # æå–å…±äº«æ•°æ®
            shared_data = self._extract_shared_data_from_results(results)
            
            # æ›´æ–°å·¥ä½œæµä¸Šä¸‹æ–‡
            if "shared_data" not in workflow_context:
                workflow_context["shared_data"] = {}
            
            workflow_context["shared_data"].update(shared_data)
            
            # è®°å½•åŒæ­¥ä¿¡æ¯
            self.logger.info(f"Synchronized {len(shared_data)} data items across agents")
            
        except Exception as e:
            self.logger.error(f"Error synchronizing agent data: {str(e)}")
    
    def _estimate_task_duration(self, task_type: str, complexity_level: str) -> int:
        """ä¼°ç®—ä»»åŠ¡æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰."""
        base_durations = {
            "quick_search": 30,
            "trend_analysis": 60,
            "competitive_analysis": 90,
            "report_generation": 120,
            "comprehensive_analysis": 180
        }
        
        complexity_multipliers = {
            "low": 0.8,
            "medium": 1.0,
            "high": 1.5
        }
        
        base_duration = base_durations.get(task_type, 60)
        multiplier = complexity_multipliers.get(complexity_level, 1.0)
        
        return int(base_duration * multiplier)
    
    async def _generate_patent_coordination_response(self, coordination_result: CollaborationResult,
                                                   workflow_context: Dict[str, Any]) -> str:
        """ç”Ÿæˆä¸“åˆ©åè°ƒå“åº”."""
        try:
            if not coordination_result.consensus_reached:
                return f"âŒ **ä¸“åˆ©åè°ƒå¤±è´¥**\n\n{coordination_result.final_result}"
            
            # ç”ŸæˆæˆåŠŸçš„åè°ƒå“åº”
            response_parts = []
            
            # æ·»åŠ åè°ƒæ‘˜è¦
            response_parts.append(f"""# âœ… ä¸“åˆ©åˆ†æåè°ƒå®Œæˆ

**åè°ƒID**: {coordination_result.collaboration_id}
**æ‰§è¡Œç­–ç•¥**: {workflow_context.get('execution_strategy', 'Unknown')}
**å‚ä¸Agent**: {len(coordination_result.participating_agents)}ä¸ª
**ä»»åŠ¡ç±»å‹**: {workflow_context.get('task_type', 'Unknown')}
**å®Œæˆæ—¶é—´**: {datetime.now().isoformat()}

---
""")
            
            # æ·»åŠ ä¸»è¦ç»“æœ
            response_parts.append(coordination_result.final_result)
            
            # æ·»åŠ Agentæ‰§è¡Œç»Ÿè®¡
            successful_agents = len([r for r in coordination_result.individual_responses if r.confidence > 0.0])
            response_parts.append(f"""

---

## ğŸ“Š æ‰§è¡Œç»Ÿè®¡

- **æˆåŠŸAgent**: {successful_agents}/{len(coordination_result.individual_responses)}
- **å¹³å‡ç½®ä¿¡åº¦**: {sum(r.confidence for r in coordination_result.individual_responses) / len(coordination_result.individual_responses):.2f}
- **è§£å†³æ–¹æ³•**: {coordination_result.resolution_method}
""")
            
            return "\n".join(response_parts)
            
        except Exception as e:
            self.logger.error(f"Error generating coordination response: {str(e)}")
            return f"âŒ **å“åº”ç”Ÿæˆå¤±è´¥**: {str(e)}"
    
    def _generate_patent_coordination_actions(self, coordination_result: CollaborationResult,
                                            workflow_context: Dict[str, Any]) -> List[Action]:
        """ç”Ÿæˆä¸“åˆ©åè°ƒåç»­åŠ¨ä½œ."""
        actions = []
        
        try:
            # å¦‚æœæœ‰æŠ¥å‘Šç”Ÿæˆï¼Œæ·»åŠ ä¸‹è½½åŠ¨ä½œ
            if any("report" in r.agent_id.lower() for r in coordination_result.individual_responses):
                actions.append(Action(
                    action_type="download_report",
                    description="ä¸‹è½½ä¸“åˆ©åˆ†ææŠ¥å‘Š",
                    parameters={
                        "coordination_id": coordination_result.collaboration_id,
                        "format": "pdf"
                    }
                ))
            
            # å¦‚æœåˆ†ææˆåŠŸï¼Œæ·»åŠ æ·±åº¦åˆ†æé€‰é¡¹
            successful_analysis = any(
                "analysis" in r.agent_id.lower() and r.confidence > 0.5 
                for r in coordination_result.individual_responses
            )
            
            if successful_analysis:
                actions.append(Action(
                    action_type="deep_analysis",
                    description="è¿›è¡Œæ›´æ·±åº¦çš„ä¸“åˆ©åˆ†æ",
                    parameters={
                        "base_coordination_id": coordination_result.collaboration_id
                    }
                ))
            
            # æ·»åŠ é‡æ–°æ‰§è¡Œé€‰é¡¹
            actions.append(Action(
                action_type="retry_coordination",
                description="é‡æ–°æ‰§è¡Œä¸“åˆ©åˆ†æåè°ƒ",
                parameters={
                    "original_context": workflow_context
                }
            ))
            
        except Exception as e:
            self.logger.error(f"Error generating coordination actions: {str(e)}")
        
        return actions
    
    async def _validate_config(self) -> bool:
        """éªŒè¯ä¸“åˆ©åè°ƒAgenté…ç½®."""
        # å…è®¸ä¸“åˆ©åè°ƒAgentç±»å‹
        if self.agent_type != AgentType.PATENT_COORDINATOR:
            self.logger.error(f"Invalid agent type for PatentCoordinatorAgent: {self.agent_type}")
            return False
        
        # æ£€æŸ¥æ¨èçš„èƒ½åŠ›
        recommended_capabilities = ["ä¸“åˆ©å·¥ä½œæµåè°ƒ", "Agentè°ƒåº¦", "ç»“æœæ•´åˆ"]
        if not any(cap in self.config.capabilities for cap in recommended_capabilities):
            self.logger.warning("PatentCoordinatorAgent missing recommended capabilities")
        
        return True