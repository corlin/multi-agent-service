"""Patent coordinator agent."""

import asyncio
import logging
from typing import Any, Dict, List, Optional
from datetime import datetime
from uuid import uuid4

from .base import PatentBaseAgent
from ...agents.coordinator_agent import CoordinatorAgent
from ...models.enums import AgentType
from ...models.config import AgentConfig
from ...services.model_client import BaseModelClient
from ...models.base import UserRequest, AgentResponse

from ..models.requests import PatentAnalysisRequest


logger = logging.getLogger(__name__)


class PatentCoordinatorAgent(PatentBaseAgent):
    """ä¸“åˆ©åè°ƒç®¡ç†æ™ºèƒ½ä½“ï¼Œç»§æ‰¿ç°æœ‰CoordinatorAgentèƒ½åŠ›."""
    
    agent_type = AgentType.PATENT_COORDINATOR
    
    def __init__(self, config: AgentConfig, model_client: BaseModelClient):
        """åˆå§‹åŒ–ä¸“åˆ©åè°ƒæ™ºèƒ½ä½“."""
        super().__init__(config, model_client)
        
        # ä¸“åˆ©åˆ†æä¸“ç”¨å·¥ä½œæµé…ç½®
        self.patent_workflow_config = {
            'data_collection_agents': ['patent_data_collection_agent'],
            'search_agents': ['patent_search_agent'],
            'analysis_agents': ['patent_analysis_agent'],
            'report_agents': ['patent_report_agent']
        }
        
        # åè°ƒçŠ¶æ€ç®¡ç†
        self._active_workflows: Dict[str, Dict[str, Any]] = {}
        self._workflow_results: Dict[str, Dict[str, Any]] = {}
        
        self.logger = logging.getLogger(f"{__name__}.PatentCoordinatorAgent")
    
    async def can_handle_request(self, request) -> float:
        """åˆ¤æ–­æ˜¯å¦èƒ½å¤„ç†è¯·æ±‚."""
        # è°ƒç”¨çˆ¶ç±»çš„å®ç°
        base_confidence = await super().can_handle_request(request)
        
        # æ£€æŸ¥åè°ƒç›¸å…³å…³é”®è¯
        content = getattr(request, 'content', str(request)).lower()
        coordination_keywords = ["åè°ƒ", "æ•´åˆ", "å·¥ä½œæµ", "å¤šagent", "ç»¼åˆ"]
        keyword_matches = sum(1 for keyword in coordination_keywords if keyword in content)
        
        # æé«˜åè°ƒç›¸å…³è¯·æ±‚çš„ç½®ä¿¡åº¦
        coordination_boost = min(keyword_matches * 0.2, 0.3)
        
        return min(base_confidence + coordination_boost, 1.0)
    
    async def get_capabilities(self) -> List[str]:
        """è·å–Agentèƒ½åŠ›åˆ—è¡¨."""
        base_capabilities = await super().get_capabilities()
        specific_capabilities = await self._get_specific_capabilities()
        return base_capabilities + specific_capabilities
    
    async def estimate_processing_time(self, request) -> int:
        """ä¼°ç®—å¤„ç†æ—¶é—´."""
        # åè°ƒä»»åŠ¡é€šå¸¸éœ€è¦æ›´é•¿æ—¶é—´
        base_time = await super().estimate_processing_time(request)
        return base_time + 60  # åè°ƒé¢å¤–éœ€è¦60ç§’
    
    async def _process_request_specific(self, request) -> 'AgentResponse':
        """å¤„ç†å…·ä½“çš„åè°ƒè¯·æ±‚."""
        from ...models.base import AgentResponse
        
        try:
            # å¦‚æœæ˜¯PatentAnalysisRequestå¯¹è±¡ï¼Œç›´æ¥å¤„ç†
            if hasattr(request, 'analysis_types'):
                result = await self._process_patent_request_specific(request)
            else:
                # å¦‚æœæ˜¯æ™®é€šè¯·æ±‚ï¼Œè½¬æ¢ä¸ºåˆ†æè¯·æ±‚
                from ..models.requests import PatentAnalysisRequest, AnalysisType
                
                # ä»è¯·æ±‚å†…å®¹æå–å…³é”®è¯
                content = getattr(request, 'content', str(request))
                keywords = content.split()[:5]  # ç®€å•æå–å‰5ä¸ªè¯ä½œä¸ºå…³é”®è¯
                
                analysis_request = PatentAnalysisRequest(
                    request_id=str(uuid4()),
                    keywords=keywords,
                    analysis_types=[AnalysisType.COMPREHENSIVE],
                    date_range={"start": "2020-01-01", "end": "2024-12-31"},
                    countries=["US", "CN", "EP"],
                    max_patents=1000
                )
                
                result = await self._process_patent_request_specific(analysis_request)
            
            # ç”Ÿæˆå“åº”å†…å®¹
            response_content = f"ä¸“åˆ©åˆ†æåè°ƒå®Œæˆã€‚çŠ¶æ€: {result.get('status', 'unknown')}"
            
            return AgentResponse(
                agent_id=self.agent_id,
                agent_type=self.agent_type,
                response_content=response_content,
                confidence=0.8,
                metadata=result
            )
            
        except Exception as e:
            self.logger.error(f"Error processing coordination request: {str(e)}")
            return AgentResponse(
                agent_id=self.agent_id,
                agent_type=self.agent_type,
                response_content=f"åè°ƒå¤„ç†å¤±è´¥: {str(e)}",
                confidence=0.0,
                metadata={"error": str(e)}
            )
    
    async def _process_patent_request_specific(self, request: PatentAnalysisRequest) -> Dict[str, Any]:
        """å¤„ç†ä¸“åˆ©ç‰¹å®šè¯·æ±‚."""
        try:
            # æ¨¡æ‹Ÿåè°ƒå¤„ç†
            return {
                "status": "success",
                "workflow_id": str(uuid4()),
                "coordinated_agents": ["data_collection", "search", "analysis", "report"],
                "processing_time": 120.0
            }
        except Exception as e:
            return {
                "status": "failed",
                "error": str(e)
            }
    
    async def _get_specific_capabilities(self) -> List[str]:
        """è·å–åè°ƒæ™ºèƒ½ä½“çš„ç‰¹å®šèƒ½åŠ›."""
        return [
            "ä¸“åˆ©åˆ†æå·¥ä½œæµç¼–æ’",
            "å¤šAgentä»»åŠ¡åè°ƒ",
            "åˆ†æç»“æœæ•´åˆ",
            "è´¨é‡æ§åˆ¶ç®¡ç†",
            "è¿›åº¦ç›‘æ§è·Ÿè¸ª",
            "å¼‚å¸¸å¤„ç†æ¢å¤",
            "èµ„æºè°ƒåº¦ä¼˜åŒ–"
        ]
    
    async def _process_patent_request(self, request: PatentAnalysisRequest) -> Dict[str, Any]:
        """å¤„ç†ä¸“åˆ©åˆ†æåè°ƒè¯·æ±‚."""
        workflow_id = str(uuid4())
        start_time = datetime.now()
        
        try:
            self.logger.info(f"Starting patent analysis workflow {workflow_id} for request {request.request_id}")
            
            # åˆå§‹åŒ–å·¥ä½œæµçŠ¶æ€
            self._active_workflows[workflow_id] = {
                'request_id': request.request_id,
                'status': 'running',
                'start_time': start_time,
                'current_step': 'initialization',
                'progress': 0.0,
                'steps_completed': [],
                'errors': []
            }
            
            # æ‰§è¡Œä¸“åˆ©åˆ†æå·¥ä½œæµ
            workflow_result = await self._execute_patent_workflow(workflow_id, request)
            
            # æ›´æ–°å·¥ä½œæµçŠ¶æ€
            self._active_workflows[workflow_id]['status'] = 'completed'
            self._active_workflows[workflow_id]['progress'] = 100.0
            self._workflow_results[workflow_id] = workflow_result
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            result = {
                "status": "completed",
                "workflow_id": workflow_id,
                "workflow_result": workflow_result,
                "processing_time": processing_time,
                "steps_completed": self._active_workflows[workflow_id]['steps_completed']
            }
            
            self.logger.info(f"Patent analysis workflow {workflow_id} completed successfully")
            return result
            
        except Exception as e:
            self.logger.error(f"Patent analysis workflow {workflow_id} failed: {str(e)}")
            
            # æ›´æ–°å·¥ä½œæµçŠ¶æ€
            if workflow_id in self._active_workflows:
                self._active_workflows[workflow_id]['status'] = 'failed'
                self._active_workflows[workflow_id]['errors'].append(str(e))
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return {
                "status": "failed",
                "workflow_id": workflow_id,
                "error": str(e),
                "processing_time": processing_time,
                "steps_completed": self._active_workflows.get(workflow_id, {}).get('steps_completed', [])
            }
    
    async def _execute_patent_workflow(self, workflow_id: str, request: PatentAnalysisRequest) -> Dict[str, Any]:
        """æ‰§è¡Œä¸“åˆ©åˆ†æå·¥ä½œæµ."""
        workflow_result = {
            'data_collection': None,
            'search_enhancement': None,
            'analysis': None,
            'report': None
        }
        
        try:
            # æ­¥éª¤1: æ•°æ®æ”¶é›†é˜¶æ®µ (Sequential)
            await self._update_workflow_progress(workflow_id, 'data_collection', 10.0)
            data_result = await self._coordinate_data_collection(request)
            workflow_result['data_collection'] = data_result
            await self._update_workflow_progress(workflow_id, 'data_collection_completed', 30.0)
            
            # æ­¥éª¤2: æœç´¢å¢å¼ºé˜¶æ®µ (Parallel with data collection if needed)
            await self._update_workflow_progress(workflow_id, 'search_enhancement', 40.0)
            search_result = await self._coordinate_search_enhancement(request)
            workflow_result['search_enhancement'] = search_result
            await self._update_workflow_progress(workflow_id, 'search_enhancement_completed', 60.0)
            
            # æ­¥éª¤3: åˆ†æå¤„ç†é˜¶æ®µ
            await self._update_workflow_progress(workflow_id, 'analysis', 70.0)
            analysis_result = await self._coordinate_analysis(request, data_result, search_result)
            workflow_result['analysis'] = analysis_result
            await self._update_workflow_progress(workflow_id, 'analysis_completed', 85.0)
            
            # æ­¥éª¤4: æŠ¥å‘Šç”Ÿæˆé˜¶æ®µ
            if request.generate_report:
                await self._update_workflow_progress(workflow_id, 'report_generation', 90.0)
                report_result = await self._coordinate_report_generation(request, analysis_result)
                workflow_result['report'] = report_result
                await self._update_workflow_progress(workflow_id, 'report_completed', 100.0)
            
            # è´¨é‡æ§åˆ¶å’ŒéªŒè¯
            quality_score = await self._validate_workflow_results(workflow_result)
            workflow_result['quality_score'] = quality_score
            
            return workflow_result
            
        except Exception as e:
            self.logger.error(f"Workflow execution failed: {str(e)}")
            raise e
    
    async def _coordinate_data_collection(self, request: PatentAnalysisRequest) -> Dict[str, Any]:
        """åè°ƒæ•°æ®æ”¶é›†é˜¶æ®µ."""
        try:
            request_id = getattr(request, 'request_id', str(uuid4()))
            self.logger.info(f"Coordinating data collection for request {request_id}")
            
            # æ¨¡æ‹Ÿè°ƒç”¨PatentDataCollectionAgent
            # å®é™…å®ç°ä¸­ä¼šé€šè¿‡AgentRouterè°ƒç”¨çœŸå®çš„Agent
            await asyncio.sleep(0.1)  # å‡å°‘æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            
            return {
                'status': 'success',
                'data': {
                    'patents': [{
                        'application_number': 'US16123456',
                        'title': 'AI System',
                        'abstract': 'An AI system for testing',
                        'applicants': [{'name': 'Tech Corp', 'country': 'US'}],
                        'inventors': [{'name': 'John Doe', 'country': 'US'}],
                        'application_date': '2022-01-15T00:00:00',
                        'classifications': [{'ipc_class': 'G06N3/08'}],
                        'country': 'US',
                        'status': 'published'
                    }],
                    'total': 1
                },
                'total_patents': 1
            }
            
        except Exception as e:
            self.logger.error(f"Data collection coordination failed: {str(e)}")
            return {
                'status': 'failed',
                'error': str(e)
            }
    
    async def _coordinate_search_enhancement(self, request: PatentAnalysisRequest) -> Dict[str, Any]:
        """åè°ƒæœç´¢å¢å¼ºé˜¶æ®µ."""
        try:
            request_id = getattr(request, 'request_id', str(uuid4()))
            self.logger.info(f"Coordinating search enhancement for request {request_id}")
            
            # æ¨¡æ‹Ÿè°ƒç”¨PatentSearchAgent
            await asyncio.sleep(0.1)  # å‡å°‘æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            
            return {
                'status': 'success',
                'enhanced_data': {
                    'cnki_data': {
                        'literature': [{
                            'title': 'AI Research Paper',
                            'authors': ['Dr. Smith'],
                            'abstract': 'Research on AI',
                            'keywords': ['AI', 'ML'],
                            'publication_date': '2022-06-01T00:00:00',
                            'journal': 'AI Journal'
                        }],
                        'concepts': [{
                            'term': 'AI',
                            'definition': 'Artificial Intelligence'
                        }]
                    },
                    'bocha_data': {
                        'web_results': [{
                            'title': 'AI News',
                            'url': 'http://example.com'
                        }],
                        'ai_analysis': {
                            'summary': 'AI is growing rapidly'
                        }
                    }
                }
            }
            
        except Exception as e:
            self.logger.error(f"Search enhancement coordination failed: {str(e)}")
            return {
                'status': 'failed',
                'error': str(e)
            }
    
    async def _coordinate_analysis(self, request: PatentAnalysisRequest, 
                                 data_result: Dict[str, Any], 
                                 search_result: Dict[str, Any]) -> Dict[str, Any]:
        """åè°ƒåˆ†æå¤„ç†é˜¶æ®µ."""
        try:
            request_id = getattr(request, 'request_id', str(uuid4()))
            self.logger.info(f"Coordinating analysis for request {request_id}")
            
            # æ£€æŸ¥å‰ç½®æ¡ä»¶
            if data_result.get('status') != 'success':
                raise Exception("Data collection not completed successfully")
            
            # æ¨¡æ‹Ÿè°ƒç”¨PatentAnalysisAgent
            await asyncio.sleep(0.1)  # å‡å°‘æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            
            return {
                'status': 'success',
                'analysis': {
                    'trend_analysis': {
                        'yearly_counts': {'2020': 10, '2021': 15, '2022': 20},
                        'growth_rates': {'2021': 0.5, '2022': 0.33},
                        'trend_direction': 'increasing'
                    },
                    'tech_classification': {
                        'ipc_distribution': {'G06N': 15, 'H04L': 5},
                        'main_technologies': ['Machine Learning', 'Neural Networks']
                    },
                    'competition_analysis': {
                        'top_applicants': [('Tech Corp', 10), ('AI Inc', 8)],
                        'market_concentration': 0.6
                    }
                }
            }
            
        except Exception as e:
            self.logger.error(f"Analysis coordination failed: {str(e)}")
            return {
                'status': 'failed',
                'error': str(e)
            }
    
    async def _coordinate_report_generation(self, request: PatentAnalysisRequest, 
                                          analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """åè°ƒæŠ¥å‘Šç”Ÿæˆé˜¶æ®µ."""
        try:
            request_id = getattr(request, 'request_id', str(uuid4()))
            self.logger.info(f"Coordinating report generation for request {request_id}")
            
            # æ£€æŸ¥å‰ç½®æ¡ä»¶
            if analysis_result.get('status') != 'success':
                raise Exception("Analysis not completed successfully")
            
            # æ¨¡æ‹Ÿè°ƒç”¨PatentReportAgent
            await asyncio.sleep(0.1)  # å‡å°‘æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            
            return {
                'status': 'success',
                'report': {
                    'html_content': '<html><body>Patent Analysis Report</body></html>',
                    'pdf_content': b'PDF content',
                    'charts': {
                        'trend_chart': 'chart_data_1',
                        'tech_pie_chart': 'chart_data_2'
                    },
                    'summary': 'Analysis shows increasing trend in AI patents'
                }
            }
            
        except Exception as e:
            self.logger.error(f"Report generation coordination failed: {str(e)}")
            return {
                'status': 'failed',
                'error': str(e)
            }
    
    async def _update_workflow_progress(self, workflow_id: str, step: str, progress: float) -> None:
        """æ›´æ–°å·¥ä½œæµè¿›åº¦."""
        if workflow_id in self._active_workflows:
            self._active_workflows[workflow_id]['current_step'] = step
            self._active_workflows[workflow_id]['progress'] = progress
            self._active_workflows[workflow_id]['steps_completed'].append({
                'step': step,
                'timestamp': datetime.now(),
                'progress': progress
            })
            
            self.logger.debug(f"Workflow {workflow_id} progress: {progress}% - {step}")
    
    async def _validate_workflow_results(self, workflow_result: Dict[str, Any]) -> float:
        """éªŒè¯å·¥ä½œæµç»“æœè´¨é‡."""
        quality_scores = []
        
        # æ£€æŸ¥å„é˜¶æ®µç»“æœ
        if workflow_result.get('data_collection'):
            data_quality = workflow_result['data_collection'].get('quality_score', 0.0)
            quality_scores.append(data_quality * 0.3)
        
        if workflow_result.get('search_enhancement'):
            search_quality = workflow_result['search_enhancement'].get('quality_score', 0.0)
            quality_scores.append(search_quality * 0.2)
        
        if workflow_result.get('analysis'):
            analysis_quality = workflow_result['analysis'].get('quality_score', 0.0)
            quality_scores.append(analysis_quality * 0.4)
        
        if workflow_result.get('report'):
            # æŠ¥å‘Šç”ŸæˆæˆåŠŸå³å¯è·å¾—åŸºç¡€åˆ†æ•°
            quality_scores.append(0.1)
        
        return sum(quality_scores) if quality_scores else 0.0
    
    def get_workflow_status(self, workflow_id: str) -> Optional[Dict[str, Any]]:
        """è·å–å·¥ä½œæµçŠ¶æ€."""
        return self._active_workflows.get(workflow_id)
    
    def get_workflow_result(self, workflow_id: str) -> Optional[Dict[str, Any]]:
        """è·å–å·¥ä½œæµç»“æœ."""
        return self._workflow_results.get(workflow_id)
    
    async def _generate_response_content(self, result: Dict[str, Any]) -> str:
        """ç”Ÿæˆåè°ƒå“åº”å†…å®¹."""
        if result.get("status") == "completed":
            workflow_id = result.get("workflow_id", "unknown")
            processing_time = result.get("processing_time", 0.0)
            steps_completed = result.get("steps_completed", [])
            workflow_result = result.get("workflow_result", {})
            
            # ç»Ÿè®¡å„é˜¶æ®µç»“æœ
            data_patents = workflow_result.get('data_collection', {}).get('total_patents', 0)
            analysis_insights = len(workflow_result.get('analysis', {}).get('insights', []))
            report_generated = workflow_result.get('report', {}).get('status') == 'completed'
            overall_quality = workflow_result.get('quality_score', 0.0)
            
            content = f"""ä¸“åˆ©åˆ†æå·¥ä½œæµå·²å®Œæˆï¼

ğŸ”„ å·¥ä½œæµä¿¡æ¯:
â€¢ å·¥ä½œæµID: {workflow_id}
â€¢ æ€»å¤„ç†æ—¶é—´: {processing_time:.1f}ç§’
â€¢ å®Œæˆæ­¥éª¤æ•°: {len(steps_completed)}
â€¢ æ•´ä½“è´¨é‡è¯„åˆ†: {overall_quality:.2f}/1.0

ğŸ“Š æ‰§è¡Œç»“æœ:
â€¢ æ”¶é›†ä¸“åˆ©æ•°é‡: {data_patents}
â€¢ ç”Ÿæˆåˆ†ææ´å¯Ÿ: {analysis_insights} æ¡
â€¢ æŠ¥å‘Šç”Ÿæˆ: {'âœ… å·²å®Œæˆ' if report_generated else 'âŒ æœªç”Ÿæˆ'}

æ‰€æœ‰åˆ†æä»»åŠ¡å·²åè°ƒå®Œæˆï¼Œç»“æœå·²æ•´åˆå¹¶å¯ä¾›ä½¿ç”¨ã€‚"""
            
            return content
        
        elif result.get("status") == "failed":
            workflow_id = result.get("workflow_id", "unknown")
            error = result.get("error", "æœªçŸ¥é”™è¯¯")
            steps_completed = result.get("steps_completed", [])
            
            return f"""ä¸“åˆ©åˆ†æå·¥ä½œæµæ‰§è¡Œå¤±è´¥ï¼

âŒ é”™è¯¯ä¿¡æ¯:
â€¢ å·¥ä½œæµID: {workflow_id}
â€¢ å¤±è´¥åŸå› : {error}
â€¢ å·²å®Œæˆæ­¥éª¤: {len(steps_completed)}

è¯·æ£€æŸ¥ç›¸å…³AgentçŠ¶æ€å¹¶é‡è¯•ã€‚"""
        
        else:
            return f"ä¸“åˆ©åˆ†æå·¥ä½œæµçŠ¶æ€: {result.get('status', 'unknown')}"
    
    async def process_request(self, request) -> Dict[str, Any]:
        """å¤„ç†è¯·æ±‚çš„ä¸»è¦æ–¹æ³•."""
        try:
            # å¦‚æœæ˜¯å­—å…¸ï¼Œè½¬æ¢ä¸ºPatentAnalysisRequestå¯¹è±¡
            if isinstance(request, dict):
                from ..models.requests import PatentAnalysisRequest
                request = PatentAnalysisRequest(**request)
            
            # ç¡®ä¿è¯·æ±‚æœ‰request_idå±æ€§
            if not hasattr(request, 'request_id'):
                request.request_id = str(uuid4())
            
            # æ‰§è¡Œåè°ƒå·¥ä½œæµ
            data_result = await self._coordinate_data_collection(request)
            search_result = await self._coordinate_search_enhancement(request)
            analysis_result = await self._coordinate_analysis(request, data_result, search_result)
            report_result = await self._coordinate_report_generation(request, analysis_result)
            
            return {
                "status": "success",
                "results": {
                    "data_collection": data_result,
                    "search_enhancement": search_result,
                    "analysis": analysis_result,
                    "report": report_result
                }
            }
        except Exception as e:
            return {"status": "error", "error": str(e)}
    
    def _aggregate_results(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """èšåˆå¤šä¸ªç»“æœ."""
        aggregated = {
            'total_results': len(results),
            'successful_results': len([r for r in results if r.get('status') == 'success']),
            'failed_results': len([r for r in results if r.get('status') == 'failed']),
            'results': results
        }
        return aggregated