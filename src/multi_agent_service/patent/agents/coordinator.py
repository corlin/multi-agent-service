"""Patent coordinator agent."""

import asyncio
import logging
from typing import Any, Dict, List, Optional
from datetime import datetime
from uuid import uuid4

from .base import PatentBaseAgent
from ...agents.coordinator_agent import CoordinatorAgent
from ...models.enums import AgentType
from ...models.config import AgentConfig
from ...services.model_client import BaseModelClient
from ...models.base import UserRequest, AgentResponse

from ..models.requests import PatentAnalysisRequest


logger = logging.getLogger(__name__)


class PatentCoordinatorAgent(PatentBaseAgent):
    """ä¸“åˆ©åè°ƒç®¡ç†æ™ºèƒ½ä½“ï¼Œç»§æ‰¿ç°æœ‰CoordinatorAgentèƒ½åŠ›."""
    
    agent_type = AgentType.PATENT_COORDINATOR
    
    def __init__(self, config: AgentConfig, model_client: BaseModelClient):
        """åˆå§‹åŒ–ä¸“åˆ©åè°ƒæ™ºèƒ½ä½“."""
        super().__init__(config, model_client)
        
        # ä¸“åˆ©åˆ†æä¸“ç”¨å·¥ä½œæµé…ç½®
        self.patent_workflow_config = {
            'data_collection_agents': ['patent_data_collection_agent'],
            'search_agents': ['patent_search_agent'],
            'analysis_agents': ['patent_analysis_agent'],
            'report_agents': ['patent_report_agent']
        }
        
        # åè°ƒçŠ¶æ€ç®¡ç†
        self._active_workflows: Dict[str, Dict[str, Any]] = {}
        self._workflow_results: Dict[str, Dict[str, Any]] = {}
        
        self.logger = logging.getLogger(f"{__name__}.PatentCoordinatorAgent")
    
    async def _get_specific_capabilities(self) -> List[str]:
        """è·å–åè°ƒæ™ºèƒ½ä½“çš„ç‰¹å®šèƒ½åŠ›."""
        return [
            "ä¸“åˆ©åˆ†æå·¥ä½œæµç¼–æ’",
            "å¤šAgentä»»åŠ¡åè°ƒ",
            "åˆ†æç»“æœæ•´åˆ",
            "è´¨é‡æ§åˆ¶ç®¡ç†",
            "è¿›åº¦ç›‘æ§è·Ÿè¸ª",
            "å¼‚å¸¸å¤„ç†æ¢å¤",
            "èµ„æºè°ƒåº¦ä¼˜åŒ–"
        ]
    
    async def _process_patent_request(self, request: PatentAnalysisRequest) -> Dict[str, Any]:
        """å¤„ç†ä¸“åˆ©åˆ†æåè°ƒè¯·æ±‚."""
        workflow_id = str(uuid4())
        start_time = datetime.now()
        
        try:
            self.logger.info(f"Starting patent analysis workflow {workflow_id} for request {request.request_id}")
            
            # åˆå§‹åŒ–å·¥ä½œæµçŠ¶æ€
            self._active_workflows[workflow_id] = {
                'request_id': request.request_id,
                'status': 'running',
                'start_time': start_time,
                'current_step': 'initialization',
                'progress': 0.0,
                'steps_completed': [],
                'errors': []
            }
            
            # æ‰§è¡Œä¸“åˆ©åˆ†æå·¥ä½œæµ
            workflow_result = await self._execute_patent_workflow(workflow_id, request)
            
            # æ›´æ–°å·¥ä½œæµçŠ¶æ€
            self._active_workflows[workflow_id]['status'] = 'completed'
            self._active_workflows[workflow_id]['progress'] = 100.0
            self._workflow_results[workflow_id] = workflow_result
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            result = {
                "status": "completed",
                "workflow_id": workflow_id,
                "workflow_result": workflow_result,
                "processing_time": processing_time,
                "steps_completed": self._active_workflows[workflow_id]['steps_completed']
            }
            
            self.logger.info(f"Patent analysis workflow {workflow_id} completed successfully")
            return result
            
        except Exception as e:
            self.logger.error(f"Patent analysis workflow {workflow_id} failed: {str(e)}")
            
            # æ›´æ–°å·¥ä½œæµçŠ¶æ€
            if workflow_id in self._active_workflows:
                self._active_workflows[workflow_id]['status'] = 'failed'
                self._active_workflows[workflow_id]['errors'].append(str(e))
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return {
                "status": "failed",
                "workflow_id": workflow_id,
                "error": str(e),
                "processing_time": processing_time,
                "steps_completed": self._active_workflows.get(workflow_id, {}).get('steps_completed', [])
            }
    
    async def _execute_patent_workflow(self, workflow_id: str, request: PatentAnalysisRequest) -> Dict[str, Any]:
        """æ‰§è¡Œä¸“åˆ©åˆ†æå·¥ä½œæµ."""
        workflow_result = {
            'data_collection': None,
            'search_enhancement': None,
            'analysis': None,
            'report': None
        }
        
        try:
            # æ­¥éª¤1: æ•°æ®æ”¶é›†é˜¶æ®µ (Sequential)
            await self._update_workflow_progress(workflow_id, 'data_collection', 10.0)
            data_result = await self._coordinate_data_collection(request)
            workflow_result['data_collection'] = data_result
            await self._update_workflow_progress(workflow_id, 'data_collection_completed', 30.0)
            
            # æ­¥éª¤2: æœç´¢å¢å¼ºé˜¶æ®µ (Parallel with data collection if needed)
            await self._update_workflow_progress(workflow_id, 'search_enhancement', 40.0)
            search_result = await self._coordinate_search_enhancement(request)
            workflow_result['search_enhancement'] = search_result
            await self._update_workflow_progress(workflow_id, 'search_enhancement_completed', 60.0)
            
            # æ­¥éª¤3: åˆ†æå¤„ç†é˜¶æ®µ
            await self._update_workflow_progress(workflow_id, 'analysis', 70.0)
            analysis_result = await self._coordinate_analysis(request, data_result, search_result)
            workflow_result['analysis'] = analysis_result
            await self._update_workflow_progress(workflow_id, 'analysis_completed', 85.0)
            
            # æ­¥éª¤4: æŠ¥å‘Šç”Ÿæˆé˜¶æ®µ
            if request.generate_report:
                await self._update_workflow_progress(workflow_id, 'report_generation', 90.0)
                report_result = await self._coordinate_report_generation(request, analysis_result)
                workflow_result['report'] = report_result
                await self._update_workflow_progress(workflow_id, 'report_completed', 100.0)
            
            # è´¨é‡æ§åˆ¶å’ŒéªŒè¯
            quality_score = await self._validate_workflow_results(workflow_result)
            workflow_result['quality_score'] = quality_score
            
            return workflow_result
            
        except Exception as e:
            self.logger.error(f"Workflow execution failed: {str(e)}")
            raise e
    
    async def _coordinate_data_collection(self, request: PatentAnalysisRequest) -> Dict[str, Any]:
        """åè°ƒæ•°æ®æ”¶é›†é˜¶æ®µ."""
        try:
            self.logger.info(f"Coordinating data collection for request {request.request_id}")
            
            # æ¨¡æ‹Ÿè°ƒç”¨PatentDataCollectionAgent
            # å®é™…å®ç°ä¸­ä¼šé€šè¿‡AgentRouterè°ƒç”¨çœŸå®çš„Agent
            await asyncio.sleep(2)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            
            return {
                'status': 'completed',
                'total_patents': 150,
                'data_sources': ['google_patents', 'patent_public_api'],
                'quality_score': 0.85,
                'processing_time': 2.0
            }
            
        except Exception as e:
            self.logger.error(f"Data collection coordination failed: {str(e)}")
            return {
                'status': 'failed',
                'error': str(e)
            }
    
    async def _coordinate_search_enhancement(self, request: PatentAnalysisRequest) -> Dict[str, Any]:
        """åè°ƒæœç´¢å¢å¼ºé˜¶æ®µ."""
        try:
            self.logger.info(f"Coordinating search enhancement for request {request.request_id}")
            
            # æ¨¡æ‹Ÿè°ƒç”¨PatentSearchAgent
            await asyncio.sleep(1.5)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            
            return {
                'status': 'completed',
                'academic_papers': 25,
                'web_intelligence': 40,
                'crawled_pages': 15,
                'quality_score': 0.78,
                'processing_time': 1.5
            }
            
        except Exception as e:
            self.logger.error(f"Search enhancement coordination failed: {str(e)}")
            return {
                'status': 'failed',
                'error': str(e)
            }
    
    async def _coordinate_analysis(self, request: PatentAnalysisRequest, 
                                 data_result: Dict[str, Any], 
                                 search_result: Dict[str, Any]) -> Dict[str, Any]:
        """åè°ƒåˆ†æå¤„ç†é˜¶æ®µ."""
        try:
            self.logger.info(f"Coordinating analysis for request {request.request_id}")
            
            # æ£€æŸ¥å‰ç½®æ¡ä»¶
            if data_result.get('status') != 'completed':
                raise Exception("Data collection not completed successfully")
            
            # æ¨¡æ‹Ÿè°ƒç”¨PatentAnalysisAgent
            await asyncio.sleep(3)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            
            return {
                'status': 'completed',
                'trend_analysis': {
                    'direction': 'increasing',
                    'growth_rate': 0.15,
                    'peak_year': 2023
                },
                'tech_classification': {
                    'main_categories': ['G06F', 'H04L', 'G06N'],
                    'emerging_tech': ['AI', 'IoT', 'Blockchain']
                },
                'competition_analysis': {
                    'top_applicants': ['Company A', 'Company B', 'Company C'],
                    'market_concentration': 0.45
                },
                'insights': [
                    'Technology shows strong growth trend',
                    'Market competition is intensifying',
                    'AI integration is becoming prevalent'
                ],
                'quality_score': 0.88,
                'processing_time': 3.0
            }
            
        except Exception as e:
            self.logger.error(f"Analysis coordination failed: {str(e)}")
            return {
                'status': 'failed',
                'error': str(e)
            }
    
    async def _coordinate_report_generation(self, request: PatentAnalysisRequest, 
                                          analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """åè°ƒæŠ¥å‘Šç”Ÿæˆé˜¶æ®µ."""
        try:
            self.logger.info(f"Coordinating report generation for request {request.request_id}")
            
            # æ£€æŸ¥å‰ç½®æ¡ä»¶
            if analysis_result.get('status') != 'completed':
                raise Exception("Analysis not completed successfully")
            
            # æ¨¡æ‹Ÿè°ƒç”¨PatentReportAgent
            await asyncio.sleep(2)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            
            return {
                'status': 'completed',
                'report_id': f"report_{request.request_id}",
                'formats': ['html', 'pdf'] if request.report_format == 'pdf' else ['html'],
                'charts_generated': 5,
                'pages': 12,
                'file_size': '2.5MB',
                'processing_time': 2.0
            }
            
        except Exception as e:
            self.logger.error(f"Report generation coordination failed: {str(e)}")
            return {
                'status': 'failed',
                'error': str(e)
            }
    
    async def _update_workflow_progress(self, workflow_id: str, step: str, progress: float) -> None:
        """æ›´æ–°å·¥ä½œæµè¿›åº¦."""
        if workflow_id in self._active_workflows:
            self._active_workflows[workflow_id]['current_step'] = step
            self._active_workflows[workflow_id]['progress'] = progress
            self._active_workflows[workflow_id]['steps_completed'].append({
                'step': step,
                'timestamp': datetime.now(),
                'progress': progress
            })
            
            self.logger.debug(f"Workflow {workflow_id} progress: {progress}% - {step}")
    
    async def _validate_workflow_results(self, workflow_result: Dict[str, Any]) -> float:
        """éªŒè¯å·¥ä½œæµç»“æœè´¨é‡."""
        quality_scores = []
        
        # æ£€æŸ¥å„é˜¶æ®µç»“æœ
        if workflow_result.get('data_collection'):
            data_quality = workflow_result['data_collection'].get('quality_score', 0.0)
            quality_scores.append(data_quality * 0.3)
        
        if workflow_result.get('search_enhancement'):
            search_quality = workflow_result['search_enhancement'].get('quality_score', 0.0)
            quality_scores.append(search_quality * 0.2)
        
        if workflow_result.get('analysis'):
            analysis_quality = workflow_result['analysis'].get('quality_score', 0.0)
            quality_scores.append(analysis_quality * 0.4)
        
        if workflow_result.get('report'):
            # æŠ¥å‘Šç”ŸæˆæˆåŠŸå³å¯è·å¾—åŸºç¡€åˆ†æ•°
            quality_scores.append(0.1)
        
        return sum(quality_scores) if quality_scores else 0.0
    
    def get_workflow_status(self, workflow_id: str) -> Optional[Dict[str, Any]]:
        """è·å–å·¥ä½œæµçŠ¶æ€."""
        return self._active_workflows.get(workflow_id)
    
    def get_workflow_result(self, workflow_id: str) -> Optional[Dict[str, Any]]:
        """è·å–å·¥ä½œæµç»“æœ."""
        return self._workflow_results.get(workflow_id)
    
    async def _generate_response_content(self, result: Dict[str, Any]) -> str:
        """ç”Ÿæˆåè°ƒå“åº”å†…å®¹."""
        if result.get("status") == "completed":
            workflow_id = result.get("workflow_id", "unknown")
            processing_time = result.get("processing_time", 0.0)
            steps_completed = result.get("steps_completed", [])
            workflow_result = result.get("workflow_result", {})
            
            # ç»Ÿè®¡å„é˜¶æ®µç»“æœ
            data_patents = workflow_result.get('data_collection', {}).get('total_patents', 0)
            analysis_insights = len(workflow_result.get('analysis', {}).get('insights', []))
            report_generated = workflow_result.get('report', {}).get('status') == 'completed'
            overall_quality = workflow_result.get('quality_score', 0.0)
            
            content = f"""ä¸“åˆ©åˆ†æå·¥ä½œæµå·²å®Œæˆï¼

ğŸ”„ å·¥ä½œæµä¿¡æ¯:
â€¢ å·¥ä½œæµID: {workflow_id}
â€¢ æ€»å¤„ç†æ—¶é—´: {processing_time:.1f}ç§’
â€¢ å®Œæˆæ­¥éª¤æ•°: {len(steps_completed)}
â€¢ æ•´ä½“è´¨é‡è¯„åˆ†: {overall_quality:.2f}/1.0

ğŸ“Š æ‰§è¡Œç»“æœ:
â€¢ æ”¶é›†ä¸“åˆ©æ•°é‡: {data_patents}
â€¢ ç”Ÿæˆåˆ†ææ´å¯Ÿ: {analysis_insights} æ¡
â€¢ æŠ¥å‘Šç”Ÿæˆ: {'âœ… å·²å®Œæˆ' if report_generated else 'âŒ æœªç”Ÿæˆ'}

æ‰€æœ‰åˆ†æä»»åŠ¡å·²åè°ƒå®Œæˆï¼Œç»“æœå·²æ•´åˆå¹¶å¯ä¾›ä½¿ç”¨ã€‚"""
            
            return content
        
        elif result.get("status") == "failed":
            workflow_id = result.get("workflow_id", "unknown")
            error = result.get("error", "æœªçŸ¥é”™è¯¯")
            steps_completed = result.get("steps_completed", [])
            
            return f"""ä¸“åˆ©åˆ†æå·¥ä½œæµæ‰§è¡Œå¤±è´¥ï¼

âŒ é”™è¯¯ä¿¡æ¯:
â€¢ å·¥ä½œæµID: {workflow_id}
â€¢ å¤±è´¥åŸå› : {error}
â€¢ å·²å®Œæˆæ­¥éª¤: {len(steps_completed)}

è¯·æ£€æŸ¥ç›¸å…³AgentçŠ¶æ€å¹¶é‡è¯•ã€‚"""
        
        else:
            return f"ä¸“åˆ©åˆ†æå·¥ä½œæµçŠ¶æ€: {result.get('status', 'unknown')}"