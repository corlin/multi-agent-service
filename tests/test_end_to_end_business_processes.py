"""ç«¯åˆ°ç«¯ä¸šåŠ¡æµç¨‹æµ‹è¯•."""

import asyncio
import pytest
from datetime import datetime
from typing import Dict, List, Any, Optional
from unittest.mock import AsyncMock, MagicMock, patch
import json

from src.multi_agent_service.models.base import UserRequest, AgentResponse, IntentResult
from src.multi_agent_service.models.enums import (
    AgentType, IntentType, Priority, AgentStatus, WorkflowType, WorkflowStatus
)
from src.multi_agent_service.models.config import AgentConfig, ModelConfig
from src.multi_agent_service.services.intent_analyzer import IntentAnalyzer
from src.multi_agent_service.services.agent_router import AgentRouter
from src.multi_agent_service.agents.registry import AgentRegistry
from src.multi_agent_service.agents.sales_agent import SalesAgent
from src.multi_agent_service.agents.customer_support_agent import CustomerSupportAgent
from src.multi_agent_service.agents.manager_agent import ManagerAgent
from src.multi_agent_service.agents.field_service_agent import FieldServiceAgent
from src.multi_agent_service.agents.coordinator_agent import CoordinatorAgent
from src.multi_agent_service.services.model_clients.mock_client import MockModelClient
from src.multi_agent_service.api.chat import router as chat_router
from src.multi_agent_service.api.agents import router as agents_router
from src.multi_agent_service.api.workflows import router as workflows_router


class MockFastAPIRequest:
    """æ¨¡æ‹ŸFastAPIè¯·æ±‚å¯¹è±¡."""
    
    def __init__(self, json_data: Dict[str, Any]):
        self._json_data = json_data
    
    async def json(self):
        return self._json_data


class TestEndToEndBusinessProcesses:
    """ç«¯åˆ°ç«¯ä¸šåŠ¡æµç¨‹æµ‹è¯•ç±»."""
    
    @pytest.fixture
    async def complete_system_setup(self):
        """å®Œæ•´ç³»ç»Ÿè®¾ç½®ï¼ŒåŒ…æ‹¬æ‰€æœ‰ç»„ä»¶."""
        # åˆ›å»ºæ¨¡åž‹å®¢æˆ·ç«¯
        from src.multi_agent_service.models.enums import ModelProvider
        model_config = ModelConfig(
            provider=ModelProvider.CUSTOM,
            model_name="mock-model",
            api_key="mock-key",
            api_base="http://mock.api"
        )
        mock_client = MockModelClient(model_config)
        
        # åˆ›å»ºæ™ºèƒ½ä½“é…ç½®
        agent_configs = {
            AgentType.SALES: AgentConfig(
                agent_id="sales_001",
                agent_type=AgentType.SALES,
                name="Sales Agent",
                description="é”€å”®ä»£è¡¨æ™ºèƒ½ä½“",
                capabilities=["sales", "consultation", "pricing"],
                llm_config=model_config,
                prompt_template="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é”€å”®ä»£è¡¨ï¼Œè¯·å¸®åŠ©å®¢æˆ·è§£ç­”é—®é¢˜ã€‚",
                max_concurrent_tasks=5
            ),
            AgentType.CUSTOMER_SUPPORT: AgentConfig(
                agent_id="support_001",
                agent_type=AgentType.CUSTOMER_SUPPORT,
                name="Support Agent",
                description="å®¢æœä¸“å‘˜æ™ºèƒ½ä½“",
                capabilities=["support", "troubleshooting", "customer_service"],
                llm_config=model_config,
                prompt_template="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®¢æœä¸“å‘˜ï¼Œè¯·å¸®åŠ©å®¢æˆ·è§£å†³é—®é¢˜ã€‚",
                max_concurrent_tasks=5
            ),
            AgentType.MANAGER: AgentConfig(
                agent_id="manager_001",
                agent_type=AgentType.MANAGER,
                name="Manager Agent",
                description="ç®¡ç†è€…æ™ºèƒ½ä½“",
                capabilities=["management", "decision_making", "strategy"],
                llm_config=model_config,
                prompt_template="ä½ æ˜¯ä¸€ä¸ªå…¬å¸ç®¡ç†è€…ï¼Œè¯·æä¾›ç®¡ç†å†³ç­–å’Œæˆ˜ç•¥å»ºè®®ã€‚",
                max_concurrent_tasks=3
            ),
            AgentType.FIELD_SERVICE: AgentConfig(
                agent_id="field_001",
                agent_type=AgentType.FIELD_SERVICE,
                name="Field Service Agent",
                description="çŽ°åœºæœåŠ¡äººå‘˜æ™ºèƒ½ä½“",
                capabilities=["technical_service", "field_work", "maintenance"],
                llm_config=model_config,
                prompt_template="ä½ æ˜¯ä¸€ä¸ªçŽ°åœºæœåŠ¡æŠ€æœ¯äººå‘˜ï¼Œè¯·æä¾›æŠ€æœ¯æ”¯æŒå’Œç»´ä¿®æŒ‡å¯¼ã€‚",
                max_concurrent_tasks=3
            ),
            AgentType.COORDINATOR: AgentConfig(
                agent_id="coordinator_001",
                agent_type=AgentType.COORDINATOR,
                name="Coordinator Agent",
                description="åè°ƒå‘˜æ™ºèƒ½ä½“",
                capabilities=["coordination", "task_management", "conflict_resolution"],
                llm_config=model_config,
                prompt_template="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ä½“åè°ƒå‘˜ï¼Œè´Ÿè´£ä»»åŠ¡åˆ†é…å’Œåè°ƒç®¡ç†ã€‚",
                max_concurrent_tasks=10
            )
        }
        
        # åˆ›å»ºæ™ºèƒ½ä½“å®žä¾‹
        agents = {
            AgentType.SALES: SalesAgent(agent_configs[AgentType.SALES], mock_client),
            AgentType.CUSTOMER_SUPPORT: CustomerSupportAgent(agent_configs[AgentType.CUSTOMER_SUPPORT], mock_client),
            AgentType.MANAGER: ManagerAgent(agent_configs[AgentType.MANAGER], mock_client),
            AgentType.FIELD_SERVICE: FieldServiceAgent(agent_configs[AgentType.FIELD_SERVICE], mock_client),
            AgentType.COORDINATOR: CoordinatorAgent(agent_configs[AgentType.COORDINATOR], mock_client)
        }
        
        # åˆå§‹åŒ–æ‰€æœ‰æ™ºèƒ½ä½“
        for agent in agents.values():
            await agent.initialize()
            await agent.start()
        
        # åˆ›å»ºæ™ºèƒ½ä½“æ³¨å†Œè¡¨
        agent_registry = AgentRegistry()
        for agent in agents.values():
            await agent_registry.register_agent(agent)
        
        # åˆ›å»ºæ„å›¾åˆ†æžå™¨
        intent_analyzer = IntentAnalyzer()
        await intent_analyzer.initialize()
        
        # åˆ›å»ºæ™ºèƒ½ä½“è·¯ç”±å™¨
        agent_router = AgentRouter(intent_analyzer, agent_registry)
        
        # åˆ›å»ºAPIå®žä¾‹
        chat_api = ChatAPI(agent_router, agent_registry)
        agents_api = AgentsAPI(agent_registry)
        workflows_api = WorkflowsAPI()
        
        return {
            "agents": agents,
            "agent_registry": agent_registry,
            "intent_analyzer": intent_analyzer,
            "agent_router": agent_router,
            "chat_api": chat_api,
            "agents_api": agents_api,
            "workflows_api": workflows_api
        }

    @pytest.mark.asyncio
    async def test_sales_consultation_complete_flow(self, complete_system_setup):
        """æµ‹è¯•é”€å”®å’¨è¯¢å®Œæ•´æµç¨‹ï¼šä»Žç”¨æˆ·è¯¢é—®åˆ°æœ€ç»ˆæŠ¥ä»·."""
        system = complete_system_setup
        
        # 1. ç”¨æˆ·å‘èµ·é”€å”®å’¨è¯¢
        user_message = "ä½ å¥½ï¼Œæˆ‘æƒ³äº†è§£ä½ ä»¬çš„ä¼ä¸šç‰ˆäº§å“ï¼Œæˆ‘ä»¬æ˜¯ä¸€å®¶200äººçš„ä¸­åž‹ä¼ä¸šï¼Œä¸»è¦å…³å¿ƒä»·æ ¼å’ŒåŠŸèƒ½ã€‚"
        
        chat_request_data = {
            "messages": [
                {"role": "user", "content": user_message}
            ],
            "model": "gpt-3.5-turbo",
            "temperature": 0.7,
            "max_tokens": 1000
        }
        
        mock_request = MockFastAPIRequest(chat_request_data)
        
        # 2. é€šè¿‡Chat APIå¤„ç†è¯·æ±‚
        chat_response = await system["chat_api"].chat_completions(mock_request)
        
        # éªŒè¯åˆå§‹å“åº”
        assert chat_response is not None
        assert "choices" in chat_response
        assert len(chat_response["choices"]) > 0
        
        initial_response = chat_response["choices"][0]["message"]["content"]
        assert "ä¼ä¸šç‰ˆ" in initial_response or "äº§å“" in initial_response
        
        # 3. ç”¨æˆ·è¯¢é—®å…·ä½“ä»·æ ¼
        price_inquiry = "ä¼ä¸šç‰ˆçš„å…·ä½“ä»·æ ¼æ˜¯å¤šå°‘ï¼Ÿæœ‰ä»€ä¹ˆä¼˜æƒ æ”¿ç­–å—ï¼Ÿ"
        
        price_request_data = {
            "messages": [
                {"role": "user", "content": user_message},
                {"role": "assistant", "content": initial_response},
                {"role": "user", "content": price_inquiry}
            ],
            "model": "gpt-3.5-turbo"
        }
        
        mock_price_request = MockFastAPIRequest(price_request_data)
        price_response = await system["chat_api"].chat_completions(mock_price_request)
        
        # éªŒè¯ä»·æ ¼å“åº”
        assert price_response is not None
        price_content = price_response["choices"][0]["message"]["content"]
        assert any(keyword in price_content for keyword in ["ä»·æ ¼", "Â¥", "å…ƒ", "ä¼˜æƒ "])
        
        # 4. ç”¨æˆ·è¯·æ±‚è¯¦ç»†æ–¹æ¡ˆ
        solution_request = "è¯·ä¸ºæˆ‘ä»¬å…¬å¸åˆ¶å®šä¸€ä¸ªè¯¦ç»†çš„è§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬éƒ¨ç½²è®¡åˆ’å’ŒåŸ¹è®­å®‰æŽ’ã€‚"
        
        solution_request_data = {
            "messages": [
                {"role": "user", "content": user_message},
                {"role": "assistant", "content": initial_response},
                {"role": "user", "content": price_inquiry},
                {"role": "assistant", "content": price_content},
                {"role": "user", "content": solution_request}
            ],
            "model": "gpt-3.5-turbo"
        }
        
        mock_solution_request = MockFastAPIRequest(solution_request_data)
        solution_response = await system["chat_api"].chat_completions(mock_solution_request)
        
        # éªŒè¯æ–¹æ¡ˆå“åº”
        assert solution_response is not None
        solution_content = solution_response["choices"][0]["message"]["content"]
        assert any(keyword in solution_content for keyword in ["æ–¹æ¡ˆ", "éƒ¨ç½²", "åŸ¹è®­", "è®¡åˆ’"])
        
        # 5. éªŒè¯æ•´ä¸ªé”€å”®æµç¨‹çš„è¿žè´¯æ€§
        conversation_flow = [
            user_message,
            initial_response,
            price_inquiry,
            price_content,
            solution_request,
            solution_content
        ]
        
        # éªŒè¯å¯¹è¯æµç¨‹çš„é€»è¾‘æ€§
        assert len(conversation_flow) == 6
        assert all(content.strip() for content in conversation_flow)
        
        print("Sales consultation complete flow test passed")

    @pytest.mark.asyncio
    async def test_customer_support_complete_flow(self, complete_system_setup):
        """æµ‹è¯•å®¢æœæ”¯æŒå®Œæ•´æµç¨‹ï¼šä»Žé—®é¢˜æŠ¥å‘Šåˆ°è§£å†³æ–¹æ¡ˆæä¾›."""
        system = complete_system_setup
        
        # 1. ç”¨æˆ·æŠ¥å‘Šé—®é¢˜
        problem_report = "æˆ‘åœ¨ä½¿ç”¨ä½ ä»¬çš„ç³»ç»Ÿæ—¶é‡åˆ°äº†ç™»å½•é—®é¢˜ï¼Œæ€»æ˜¯æç¤ºå¯†ç é”™è¯¯ï¼Œä½†æˆ‘ç¡®å®šå¯†ç æ˜¯æ­£ç¡®çš„ã€‚"
        
        support_request_data = {
            "messages": [
                {"role": "user", "content": problem_report}
            ],
            "model": "gpt-3.5-turbo"
        }
        
        mock_request = MockFastAPIRequest(support_request_data)
        
        # 2. å®¢æœåˆå§‹å“åº”
        initial_response = await system["chat_api"].chat_completions(mock_request)
        
        assert initial_response is not None
        initial_content = initial_response["choices"][0]["message"]["content"]
        assert any(keyword in initial_content for keyword in ["ç™»å½•", "å¯†ç ", "é—®é¢˜", "å¸®åŠ©"])
        
        # 3. ç”¨æˆ·æä¾›æ›´å¤šä¿¡æ¯
        additional_info = "æˆ‘ä½¿ç”¨çš„æ˜¯Chromeæµè§ˆå™¨ï¼Œç³»ç»Ÿç‰ˆæœ¬æ˜¯Windows 10ï¼Œè¿™ä¸ªé—®é¢˜ä»Žæ˜¨å¤©å¼€å§‹å‡ºçŽ°çš„ã€‚"
        
        info_request_data = {
            "messages": [
                {"role": "user", "content": problem_report},
                {"role": "assistant", "content": initial_content},
                {"role": "user", "content": additional_info}
            ],
            "model": "gpt-3.5-turbo"
        }
        
        mock_info_request = MockFastAPIRequest(info_request_data)
        diagnostic_response = await system["chat_api"].chat_completions(mock_info_request)
        
        # éªŒè¯è¯Šæ–­å“åº”
        assert diagnostic_response is not None
        diagnostic_content = diagnostic_response["choices"][0]["message"]["content"]
        
        # 4. ç”¨æˆ·è¯¢é—®è§£å†³æ–¹æ¡ˆ
        solution_inquiry = "æœ‰ä»€ä¹ˆè§£å†³æ–¹æ³•å—ï¼Ÿæˆ‘éœ€è¦å°½å¿«æ¢å¤ä½¿ç”¨ã€‚"
        
        solution_request_data = {
            "messages": [
                {"role": "user", "content": problem_report},
                {"role": "assistant", "content": initial_content},
                {"role": "user", "content": additional_info},
                {"role": "assistant", "content": diagnostic_content},
                {"role": "user", "content": solution_inquiry}
            ],
            "model": "gpt-3.5-turbo"
        }
        
        mock_solution_request = MockFastAPIRequest(solution_request_data)
        solution_response = await system["chat_api"].chat_completions(mock_solution_request)
        
        # éªŒè¯è§£å†³æ–¹æ¡ˆå“åº”
        assert solution_response is not None
        solution_content = solution_response["choices"][0]["message"]["content"]
        assert any(keyword in solution_content for keyword in ["è§£å†³", "æ–¹æ³•", "æ­¥éª¤", "å°è¯•"])
        
        # 5. éªŒè¯é—®é¢˜è§£å†³æµç¨‹
        support_flow = [
            problem_report,
            initial_content,
            additional_info,
            diagnostic_content,
            solution_inquiry,
            solution_content
        ]
        
        assert len(support_flow) == 6
        assert all(content.strip() for content in support_flow)
        
        print("Customer support complete flow test passed")

    @pytest.mark.asyncio
    async def test_intent_recognition_to_agent_response_pipeline(self, complete_system_setup):
        """æµ‹è¯•ä»Žæ„å›¾è¯†åˆ«åˆ°æ™ºèƒ½ä½“å“åº”çš„å®Œæ•´é“¾è·¯."""
        system = complete_system_setup
        
        # æµ‹è¯•ç”¨ä¾‹ï¼šä¸åŒç±»åž‹çš„ç”¨æˆ·è¯·æ±‚
        test_cases = [
            {
                "content": "æˆ‘æƒ³è´­ä¹°ä½ ä»¬çš„äº§å“ï¼Œè¯·ç»™æˆ‘æŠ¥ä¸ªä»·",
                "expected_intent": IntentType.SALES_INQUIRY,
                "expected_agent": AgentType.SALES,
                "keywords": ["ä»·æ ¼", "äº§å“", "è´­ä¹°"]
            },
            {
                "content": "æˆ‘çš„ç³»ç»Ÿå‡ºçŽ°äº†æ•…éšœï¼Œéœ€è¦æŠ€æœ¯æ”¯æŒ",
                "expected_intent": IntentType.TECHNICAL_SERVICE,
                "expected_agent": AgentType.FIELD_SERVICE,
                "keywords": ["æ•…éšœ", "æŠ€æœ¯", "æ”¯æŒ"]
            },
            {
                "content": "æˆ‘å¯¹æœåŠ¡ä¸æ»¡æ„ï¼Œæƒ³è¦æŠ•è¯‰",
                "expected_intent": IntentType.CUSTOMER_SUPPORT,
                "expected_agent": AgentType.CUSTOMER_SUPPORT,
                "keywords": ["æœåŠ¡", "æŠ•è¯‰", "ä¸æ»¡æ„"]
            },
            {
                "content": "æˆ‘éœ€è¦åˆ¶å®šä¸€ä¸ªé•¿æœŸçš„åˆä½œæˆ˜ç•¥",
                "expected_intent": IntentType.MANAGEMENT_DECISION,
                "expected_agent": AgentType.MANAGER,
                "keywords": ["æˆ˜ç•¥", "åˆä½œ", "é•¿æœŸ"]
            }
        ]
        
        for i, test_case in enumerate(test_cases):
            print(f"Testing case {i+1}: {test_case['content'][:50]}...")
            
            # 1. åˆ›å»ºç”¨æˆ·è¯·æ±‚
            user_request = UserRequest(
                request_id=f"intent_test_{i+1:03d}",
                content=test_case["content"],
                priority=Priority.NORMAL
            )
            
            # 2. æ„å›¾è¯†åˆ«
            intent_result = await system["intent_analyzer"].analyze_intent(user_request)
            
            # éªŒè¯æ„å›¾è¯†åˆ«ç»“æžœ
            assert intent_result is not None
            assert intent_result.intent_type is not None
            assert intent_result.confidence > 0.0
            
            # 3. æ™ºèƒ½ä½“è·¯ç”±
            route_result, _ = await system["agent_router"].route_request(user_request)
            
            # éªŒè¯è·¯ç”±ç»“æžœ
            assert route_result is not None
            assert route_result.selected_agent is not None
            assert route_result.confidence > 0.0
            
            # 4. æ™ºèƒ½ä½“å¤„ç†
            selected_agent = system["agents"][route_result.selected_agent]
            agent_response = await selected_agent.process_request(user_request)
            
            # éªŒè¯æ™ºèƒ½ä½“å“åº”
            assert agent_response is not None
            assert agent_response.response_content is not None
            assert agent_response.agent_id == selected_agent.agent_id
            assert agent_response.agent_type == route_result.selected_agent
            
            # 5. éªŒè¯å“åº”å†…å®¹çš„ç›¸å…³æ€§
            response_content = agent_response.response_content.lower()
            content_relevant = any(
                keyword in response_content 
                for keyword in test_case["keywords"]
            )
            
            # å¦‚æžœç›´æŽ¥å…³é”®è¯åŒ¹é…å¤±è´¥ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯åˆç†çš„å“åº”
            if not content_relevant:
                # æ£€æŸ¥æ˜¯å¦åŒ…å«é€šç”¨çš„æœåŠ¡æ€§è¯æ±‡
                service_keywords = ["å¸®åŠ©", "æœåŠ¡", "è§£å†³", "æä¾›", "æ”¯æŒ", "å’¨è¯¢"]
                content_relevant = any(keyword in response_content for keyword in service_keywords)
            
            assert content_relevant, f"Response not relevant to request: {test_case['content']}"
            
            print(f"  âœ“ Intent: {intent_result.intent_type}")
            print(f"  âœ“ Agent: {route_result.selected_agent}")
            print(f"  âœ“ Response length: {len(agent_response.response_content)}")
        
        print("Intent recognition to agent response pipeline test passed")

    @pytest.mark.asyncio
    async def test_api_interface_complete_business_flow(self, complete_system_setup):
        """æµ‹è¯•APIæŽ¥å£çš„å®Œæ•´ä¸šåŠ¡æµç¨‹."""
        system = complete_system_setup
        
        # 1. æµ‹è¯•æ™ºèƒ½ä½“çŠ¶æ€æŸ¥è¯¢API
        agents_status = await system["agents_api"].get_agents_status()
        
        assert agents_status is not None
        assert "agents" in agents_status
        assert len(agents_status["agents"]) > 0
        
        # éªŒè¯æ¯ä¸ªæ™ºèƒ½ä½“çš„çŠ¶æ€ä¿¡æ¯
        for agent_info in agents_status["agents"]:
            assert "agent_id" in agent_info
            assert "agent_type" in agent_info
            assert "status" in agent_info
            assert "capabilities" in agent_info
        
        # 2. æµ‹è¯•ç‰¹å®šæ™ºèƒ½ä½“ä¿¡æ¯æŸ¥è¯¢
        sales_agent_info = await system["agents_api"].get_agent_info("sales_001")
        
        assert sales_agent_info is not None
        assert sales_agent_info["agent_id"] == "sales_001"
        assert sales_agent_info["agent_type"] == "sales"
        
        # 3. æµ‹è¯•æ™ºèƒ½ä½“è·¯ç”±API
        route_request_data = {
            "content": "æˆ‘æƒ³äº†è§£äº§å“ä»·æ ¼",
            "context": {"user_type": "potential_customer"}
        }
        
        mock_route_request = MockFastAPIRequest(route_request_data)
        route_response = await system["agents_api"].route_request(mock_route_request)
        
        assert route_response is not None
        assert "selected_agent" in route_response
        assert "confidence" in route_response
        assert "reasoning" in route_response
        
        # 4. æµ‹è¯•èŠå¤©å®ŒæˆAPIçš„å®Œæ•´æµç¨‹
        chat_messages = [
            {"role": "user", "content": "ä½ å¥½ï¼Œæˆ‘éœ€è¦æŠ€æœ¯æ”¯æŒ"},
            {"role": "assistant", "content": "æ‚¨å¥½ï¼æˆ‘æ˜¯æŠ€æœ¯æ”¯æŒä¸“å‘˜ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚è¯·æè¿°æ‚¨é‡åˆ°çš„å…·ä½“é—®é¢˜ã€‚"},
            {"role": "user", "content": "æˆ‘çš„ç³»ç»Ÿæ— æ³•å¯åŠ¨ï¼Œæ˜¾ç¤ºè“å±é”™è¯¯"}
        ]
        
        chat_request_data = {
            "messages": chat_messages,
            "model": "gpt-3.5-turbo",
            "temperature": 0.7
        }
        
        mock_chat_request = MockFastAPIRequest(chat_request_data)
        chat_response = await system["chat_api"].chat_completions(mock_chat_request)
        
        # éªŒè¯èŠå¤©å“åº”
        assert chat_response is not None
        assert "choices" in chat_response
        assert len(chat_response["choices"]) > 0
        
        response_message = chat_response["choices"][0]["message"]
        assert "role" in response_message
        assert "content" in response_message
        assert response_message["role"] == "assistant"
        
        # 5. æµ‹è¯•å·¥ä½œæµæ‰§è¡ŒAPI
        workflow_request_data = {
            "workflow_type": "sequential",
            "input_data": {
                "task_description": "å¤„ç†å®¢æˆ·æŠ€æœ¯æ”¯æŒè¯·æ±‚",
                "priority": "high"
            }
        }
        
        mock_workflow_request = MockFastAPIRequest(workflow_request_data)
        
        # ç”±äºŽå·¥ä½œæµAPIå¯èƒ½éœ€è¦æ›´å¤æ‚çš„è®¾ç½®ï¼Œè¿™é‡Œä¸»è¦éªŒè¯APIç»“æž„
        try:
            workflow_response = await system["workflows_api"].execute_workflow(mock_workflow_request)
            
            if workflow_response:
                assert "execution_id" in workflow_response
                assert "status" in workflow_response
        except Exception as e:
            # å¦‚æžœå·¥ä½œæµæ‰§è¡Œå¤±è´¥ï¼Œè‡³å°‘éªŒè¯é”™è¯¯å¤„ç†
            assert isinstance(e, Exception)
            print(f"Workflow execution failed as expected: {str(e)}")
        
        print("API interface complete business flow test passed")

    @pytest.mark.asyncio
    async def test_complex_multi_step_business_scenario(self, complete_system_setup):
        """æµ‹è¯•å¤æ‚çš„å¤šæ­¥éª¤ä¸šåŠ¡åœºæ™¯."""
        system = complete_system_setup
        
        # åœºæ™¯ï¼šä¼ä¸šå®¢æˆ·çš„å®Œæ•´æœåŠ¡æµç¨‹
        # 1. åˆå§‹å’¨è¯¢ -> 2. éœ€æ±‚åˆ†æž -> 3. æ–¹æ¡ˆè®¾è®¡ -> 4. æŠ€æœ¯è¯„ä¼° -> 5. ç®¡ç†å®¡æ‰¹ -> 6. å®žæ–½è®¡åˆ’
        
        scenario_steps = [
            {
                "step": 1,
                "user_input": "æˆ‘ä»¬æ˜¯ä¸€å®¶500äººçš„åˆ¶é€ ä¼ä¸šï¼Œæƒ³è¦æ•°å­—åŒ–è½¬åž‹ï¼Œéœ€è¦äº†è§£ä½ ä»¬çš„è§£å†³æ–¹æ¡ˆ",
                "expected_agent_type": AgentType.SALES,
                "validation_keywords": ["è§£å†³æ–¹æ¡ˆ", "æ•°å­—åŒ–", "ä¼ä¸š"]
            },
            {
                "step": 2,
                "user_input": "æˆ‘ä»¬ä¸»è¦éœ€è¦ERPç³»ç»Ÿé›†æˆã€æ•°æ®åˆ†æžå¹³å°å’Œç§»åŠ¨åŠžå…¬æ”¯æŒ",
                "expected_agent_type": AgentType.SALES,
                "validation_keywords": ["ERP", "æ•°æ®åˆ†æž", "ç§»åŠ¨åŠžå…¬"]
            },
            {
                "step": 3,
                "user_input": "æŠ€æœ¯æ–¹é¢æˆ‘ä»¬æ‹…å¿ƒç³»ç»Ÿå…¼å®¹æ€§å’Œæ•°æ®è¿ç§»é—®é¢˜",
                "expected_agent_type": AgentType.FIELD_SERVICE,
                "validation_keywords": ["æŠ€æœ¯", "å…¼å®¹æ€§", "æ•°æ®è¿ç§»"]
            },
            {
                "step": 4,
                "user_input": "é¢„ç®—å¤§æ¦‚åœ¨200ä¸‡å·¦å³ï¼Œéœ€è¦ç®¡ç†å±‚å®¡æ‰¹ï¼Œä½ ä»¬èƒ½æä¾›è¯¦ç»†çš„ROIåˆ†æžå—ï¼Ÿ",
                "expected_agent_type": AgentType.MANAGER,
                "validation_keywords": ["é¢„ç®—", "ç®¡ç†å±‚", "ROI"]
            },
            {
                "step": 5,
                "user_input": "å¦‚æžœå†³å®šåˆä½œï¼Œå®žæ–½å‘¨æœŸå¤§æ¦‚å¤šé•¿ï¼Ÿéœ€è¦æˆ‘ä»¬é…åˆå“ªäº›å·¥ä½œï¼Ÿ",
                "expected_agent_type": AgentType.FIELD_SERVICE,
                "validation_keywords": ["å®žæ–½", "å‘¨æœŸ", "é…åˆ"]
            }
        ]
        
        conversation_history = []
        
        for step_info in scenario_steps:
            print(f"Processing step {step_info['step']}: {step_info['user_input'][:50]}...")
            
            # åˆ›å»ºç”¨æˆ·è¯·æ±‚
            user_request = UserRequest(
                request_id=f"scenario_step_{step_info['step']}",
                content=step_info["user_input"],
                priority=Priority.HIGH,
                context={"conversation_history": conversation_history}
            )
            
            # è·¯ç”±åˆ°åˆé€‚çš„æ™ºèƒ½ä½“
            route_result, intent_result = await system["agent_router"].route_request(user_request)
            
            # å¤„ç†è¯·æ±‚
            selected_agent = system["agents"][route_result.selected_agent]
            agent_response = await selected_agent.process_request(user_request)
            
            # éªŒè¯å“åº”
            assert agent_response is not None
            assert agent_response.response_content is not None
            
            # éªŒè¯å“åº”å†…å®¹çš„ç›¸å…³æ€§
            response_content = agent_response.response_content.lower()
            keywords_found = any(
                keyword.lower() in response_content 
                for keyword in step_info["validation_keywords"]
            )
            
            # å¦‚æžœå…³é”®è¯ä¸åŒ¹é…ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯åˆç†çš„ä¸šåŠ¡å“åº”
            if not keywords_found:
                business_keywords = [
                    "æ–¹æ¡ˆ", "æœåŠ¡", "æ”¯æŒ", "å¸®åŠ©", "æä¾›", "è§£å†³", 
                    "åˆ†æž", "è¯„ä¼°", "å»ºè®®", "å’¨è¯¢", "äº†è§£"
                ]
                keywords_found = any(keyword in response_content for keyword in business_keywords)
            
            assert keywords_found, f"Response not relevant for step {step_info['step']}"
            
            # æ›´æ–°å¯¹è¯åŽ†å²
            conversation_history.extend([
                {"role": "user", "content": step_info["user_input"]},
                {"role": "assistant", "content": agent_response.response_content, "agent_type": agent_response.agent_type.value}
            ])
            
            print(f"  âœ“ Routed to: {route_result.selected_agent}")
            print(f"  âœ“ Response length: {len(agent_response.response_content)}")
        
        # éªŒè¯æ•´ä¸ªåœºæ™¯çš„å®Œæ•´æ€§
        assert len(conversation_history) == len(scenario_steps) * 2  # æ¯æ­¥åŒ…å«ç”¨æˆ·è¾“å…¥å’Œæ™ºèƒ½ä½“å“åº”
        
        # éªŒè¯æ¶‰åŠçš„æ™ºèƒ½ä½“ç±»åž‹å¤šæ ·æ€§
        involved_agents = set()
        for i in range(1, len(conversation_history), 2):  # åªçœ‹æ™ºèƒ½ä½“å“åº”
            if "agent_type" in conversation_history[i]:
                involved_agents.add(conversation_history[i]["agent_type"])
        
        assert len(involved_agents) >= 2, "Should involve multiple agent types"
        
        print(f"Complex multi-step business scenario completed with {len(involved_agents)} agent types")

    @pytest.mark.asyncio
    async def test_error_handling_in_business_flow(self, complete_system_setup):
        """æµ‹è¯•ä¸šåŠ¡æµç¨‹ä¸­çš„é”™è¯¯å¤„ç†."""
        system = complete_system_setup
        
        # 1. æµ‹è¯•æ— æ•ˆè¾“å…¥çš„å¤„ç†
        invalid_requests = [
            "",  # ç©ºè¾“å…¥
            "   ",  # åªæœ‰ç©ºæ ¼
            "a" * 10000,  # è¿‡é•¿è¾“å…¥
            "ðŸ¤–ðŸ¤–ðŸ¤–",  # ç‰¹æ®Šå­—ç¬¦
            None  # Noneè¾“å…¥ï¼ˆéœ€è¦ç‰¹æ®Šå¤„ç†ï¼‰
        ]
        
        for i, invalid_input in enumerate(invalid_requests):
            if invalid_input is None:
                continue  # è·³è¿‡Noneè¾“å…¥ï¼Œå› ä¸ºä¼šåœ¨è¯·æ±‚åˆ›å»ºæ—¶å¤±è´¥
            
            try:
                user_request = UserRequest(
                    request_id=f"invalid_test_{i}",
                    content=invalid_input,
                    priority=Priority.NORMAL
                )
                
                # å°è¯•è·¯ç”±å’Œå¤„ç†
                route_result, intent_result = await system["agent_router"].route_request(user_request)
                
                # å³ä½¿æ˜¯æ— æ•ˆè¾“å…¥ï¼Œç³»ç»Ÿä¹Ÿåº”è¯¥èƒ½å¤Ÿå¤„ç†å¹¶è¿”å›žåˆç†çš„å“åº”
                assert route_result is not None
                assert route_result.selected_agent is not None
                
                selected_agent = system["agents"][route_result.selected_agent]
                agent_response = await selected_agent.process_request(user_request)
                
                # éªŒè¯é”™è¯¯å¤„ç†å“åº”
                assert agent_response is not None
                assert agent_response.response_content is not None
                
            except Exception as e:
                # å¦‚æžœæŠ›å‡ºå¼‚å¸¸ï¼ŒéªŒè¯æ˜¯åˆç†çš„å¼‚å¸¸
                assert isinstance(e, (ValueError, TypeError, AttributeError))
                print(f"Expected error for invalid input {i}: {str(e)}")
        
        # 2. æµ‹è¯•æ™ºèƒ½ä½“ä¸å¯ç”¨æ—¶çš„å¤„ç†
        # æ¨¡æ‹Ÿæ™ºèƒ½ä½“ç¦»çº¿
        original_status = system["agents"][AgentType.SALES]._status
        system["agents"][AgentType.SALES]._status = AgentStatus.OFFLINE
        
        try:
            sales_request = UserRequest(
                request_id="offline_agent_test",
                content="æˆ‘æƒ³è´­ä¹°äº§å“",
                priority=Priority.NORMAL
            )
            
            route_result, _ = await system["agent_router"].route_request(sales_request)
            
            # åº”è¯¥è·¯ç”±åˆ°å¤‡ç”¨æ™ºèƒ½ä½“æˆ–è¿”å›žé”™è¯¯ä¿¡æ¯
            assert route_result is not None
            
            # å¦‚æžœè·¯ç”±åˆ°äº†ç¦»çº¿çš„æ™ºèƒ½ä½“ï¼Œå¤„ç†æ—¶åº”è¯¥æœ‰é€‚å½“çš„é”™è¯¯å¤„ç†
            if route_result.selected_agent == AgentType.SALES:
                try:
                    selected_agent = system["agents"][route_result.selected_agent]
                    response = await selected_agent.process_request(sales_request)
                    # å¦‚æžœæˆåŠŸå¤„ç†ï¼ŒéªŒè¯å“åº”
                    assert response is not None
                except Exception as e:
                    # å¦‚æžœå¤±è´¥ï¼Œåº”è¯¥æ˜¯åˆç†çš„é”™è¯¯
                    assert "offline" in str(e).lower() or "unavailable" in str(e).lower()
            
        finally:
            # æ¢å¤æ™ºèƒ½ä½“çŠ¶æ€
            system["agents"][AgentType.SALES]._status = original_status
        
        # 3. æµ‹è¯•APIå±‚é¢çš„é”™è¯¯å¤„ç†
        # æµ‹è¯•æ— æ•ˆçš„èŠå¤©è¯·æ±‚
        invalid_chat_data = {
            "messages": [],  # ç©ºæ¶ˆæ¯åˆ—è¡¨
            "model": "invalid_model"
        }
        
        mock_invalid_request = MockFastAPIRequest(invalid_chat_data)
        
        try:
            chat_response = await system["chat_api"].chat_completions(mock_invalid_request)
            
            # å¦‚æžœæ²¡æœ‰æŠ›å‡ºå¼‚å¸¸ï¼ŒéªŒè¯é”™è¯¯å“åº”
            if chat_response:
                assert "error" in chat_response or "choices" in chat_response
        except Exception as e:
            # éªŒè¯æ˜¯åˆç†çš„é”™è¯¯
            assert isinstance(e, (ValueError, KeyError, AttributeError))
            print(f"Expected API error: {str(e)}")
        
        print("Error handling in business flow test passed")

    @pytest.mark.asyncio
    async def test_performance_under_concurrent_requests(self, complete_system_setup):
        """æµ‹è¯•å¹¶å‘è¯·æ±‚ä¸‹çš„ç³»ç»Ÿæ€§èƒ½."""
        system = complete_system_setup
        
        # åˆ›å»ºå¤šä¸ªå¹¶å‘è¯·æ±‚
        concurrent_requests = []
        request_types = [
            "æˆ‘æƒ³äº†è§£äº§å“ä»·æ ¼",
            "ç³»ç»Ÿå‡ºçŽ°äº†æ•…éšœ",
            "éœ€è¦æŠ€æœ¯æ”¯æŒ",
            "æƒ³è¦æŠ•è¯‰æœåŠ¡",
            "åˆ¶å®šåˆä½œæ–¹æ¡ˆ"
        ]
        
        # åˆ›å»º20ä¸ªå¹¶å‘è¯·æ±‚
        for i in range(20):
            request_content = request_types[i % len(request_types)] + f" (è¯·æ±‚ {i+1})"
            
            chat_data = {
                "messages": [{"role": "user", "content": request_content}],
                "model": "gpt-3.5-turbo"
            }
            
            mock_request = MockFastAPIRequest(chat_data)
            concurrent_requests.append(
                system["chat_api"].chat_completions(mock_request)
            )
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = datetime.now()
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰è¯·æ±‚
        results = await asyncio.gather(*concurrent_requests, return_exceptions=True)
        
        # è®°å½•ç»“æŸæ—¶é—´
        end_time = datetime.now()
        processing_time = (end_time - start_time).total_seconds()
        
        # éªŒè¯ç»“æžœ
        successful_responses = [
            result for result in results 
            if not isinstance(result, Exception) and result is not None
        ]
        
        failed_responses = [
            result for result in results 
            if isinstance(result, Exception)
        ]
        
        # éªŒè¯æ€§èƒ½æŒ‡æ ‡
        success_rate = len(successful_responses) / len(results)
        average_response_time = processing_time / len(results)
        
        print(f"Concurrent requests performance:")
        print(f"  Total requests: {len(results)}")
        print(f"  Successful: {len(successful_responses)}")
        print(f"  Failed: {len(failed_responses)}")
        print(f"  Success rate: {success_rate:.2%}")
        print(f"  Total processing time: {processing_time:.2f}s")
        print(f"  Average response time: {average_response_time:.2f}s")
        
        # æ€§èƒ½æ–­è¨€
        assert success_rate >= 0.8, f"Success rate too low: {success_rate:.2%}"
        assert average_response_time < 5.0, f"Average response time too high: {average_response_time:.2f}s"
        
        # éªŒè¯æˆåŠŸå“åº”çš„è´¨é‡
        for response in successful_responses[:5]:  # æ£€æŸ¥å‰5ä¸ªæˆåŠŸå“åº”
            assert "choices" in response
            assert len(response["choices"]) > 0
            assert "message" in response["choices"][0]
            assert "content" in response["choices"][0]["message"]
            assert len(response["choices"][0]["message"]["content"]) > 0
        
        print("Performance under concurrent requests test passed")