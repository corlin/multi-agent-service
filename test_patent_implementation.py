#!/usr/bin/env python3
"""ç®€å•æµ‹è¯•è„šæœ¬éªŒè¯ä¸“åˆ©æ•°æ®å¤„ç†å®ç°."""

import asyncio
import sys
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from src.multi_agent_service.patent.models.patent_data import (
    PatentData, PatentDataset, PatentApplicant, PatentInventor, 
    PatentClassification, DataQualityReport
)
from src.multi_agent_service.patent.utils.data_processor import (
    PatentDataStandardizer, PatentDeduplicator, PatentQualityController, PatentDataProcessor
)


async def test_patent_data_models():
    """æµ‹è¯•ä¸“åˆ©æ•°æ®æ¨¡å‹."""
    print("ğŸ§ª æµ‹è¯•ä¸“åˆ©æ•°æ®æ¨¡å‹...")
    
    try:
        # åˆ›å»ºç”³è¯·äºº
        applicant = PatentApplicant(
            name="æµ‹è¯•å…¬å¸æœ‰é™å…¬å¸",
            normalized_name="æµ‹è¯•å…¬å¸ Co., Ltd.",
            country="CN",
            applicant_type="ä¼ä¸š"
        )
        
        # åˆ›å»ºå‘æ˜äºº
        inventor = PatentInventor(
            name="å¼ ä¸‰",
            normalized_name="å¼ ä¸‰",
            country="CN"
        )
        
        # åˆ›å»ºåˆ†ç±»
        classification = PatentClassification(
            ipc_class="A01B 1/00",
            cpc_class="A01B1/00",
            national_class="A01B1/00"
        )
        
        # åˆ›å»ºä¸“åˆ©æ•°æ®
        patent = PatentData(
            application_number="CN202310123456.7",
            title="ä¸€ç§æ–°å‹å†œä¸šæœºæ¢°è£…ç½®",
            abstract="æœ¬å‘æ˜æ¶‰åŠä¸€ç§æ–°å‹å†œä¸šæœºæ¢°è£…ç½®ï¼ŒåŒ…æ‹¬ä¸»ä½“ç»“æ„ã€ä¼ åŠ¨ç³»ç»Ÿå’Œæ§åˆ¶ç³»ç»Ÿç­‰éƒ¨åˆ†ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæé«˜å†œä¸šç”Ÿäº§æ•ˆç‡ã€‚",
            applicants=[applicant],
            inventors=[inventor],
            application_date=datetime(2023, 1, 15),
            publication_date=datetime(2023, 7, 15),
            classifications=[classification],
            country="CN",
            status="å·²å…¬å¼€",
            technical_field="å†œä¸šæœºæ¢°",
            data_source="test_source",
            keywords=["å†œä¸š", "æœºæ¢°", "è£…ç½®", "è‡ªåŠ¨åŒ–"]
        )
        
        print(f"âœ… ä¸“åˆ©æ•°æ®åˆ›å»ºæˆåŠŸ:")
        print(f"   ç”³è¯·å·: {patent.application_number}")
        print(f"   æ ‡é¢˜: {patent.title}")
        print(f"   ç”³è¯·äºº: {patent.applicants[0].name}")
        print(f"   å‘æ˜äºº: {patent.inventors[0].name}")
        print(f"   å›½å®¶: {patent.country}")
        print(f"   çŠ¶æ€: {patent.status}")
        
        # è®¡ç®—è´¨é‡è¯„åˆ†
        quality_score = patent.calculate_quality_score()
        print(f"   è´¨é‡è¯„åˆ†: {quality_score:.2f}")
        
        # è·å–å“ˆå¸Œå€¼
        print(f"   å†…å®¹å“ˆå¸Œ: {patent.content_hash[:16]}...")
        print(f"   ç›¸ä¼¼æ€§å“ˆå¸Œ: {patent.similarity_hash[:16]}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ ä¸“åˆ©æ•°æ®æ¨¡å‹æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


async def test_data_standardization():
    """æµ‹è¯•æ•°æ®æ ‡å‡†åŒ–."""
    print("\nğŸ§ª æµ‹è¯•æ•°æ®æ ‡å‡†åŒ–...")
    
    try:
        standardizer = PatentDataStandardizer()
        
        # åˆ›å»ºéœ€è¦æ ‡å‡†åŒ–çš„ä¸“åˆ©æ•°æ®ï¼ˆä½¿ç”¨æœ‰æ•ˆå€¼ï¼Œç„¶åæ‰‹åŠ¨è®¾ç½®éœ€è¦æ ‡å‡†åŒ–çš„å­—æ®µï¼‰
        patent = PatentData(
            application_number="CN202310123456.7",
            title="ä¸€ç§æ–°å‹å†œä¸šæœºæ¢°è£…ç½®",
            abstract="æœ¬å‘æ˜æ¶‰åŠå†œä¸šæœºæ¢°è£…ç½®ï¼Œå…·æœ‰åˆ›æ–°æ€§ç‰¹å¾...",
            applicants=[PatentApplicant(name="æµ‹è¯•å…¬å¸æœ‰é™å…¬å¸", normalized_name="æµ‹è¯•å…¬å¸æœ‰é™å…¬å¸")],
            inventors=[PatentInventor(name="å¼ ä¸‰", normalized_name="å¼ ä¸‰")],
            application_date=datetime(2023, 1, 15),
            country="CN",
            status="ç”³è¯·ä¸­",
            data_source="test_source",
            keywords=["å†œä¸š", "æœºæ¢°", "è£…ç½®", "è‡ªåŠ¨åŒ–"]
        )
        
        # æ‰‹åŠ¨è®¾ç½®éœ€è¦æ ‡å‡†åŒ–çš„å­—æ®µï¼ˆç»•è¿‡PydanticéªŒè¯ï¼‰
        patent.application_number = "cn202310123456.7"  # å°å†™
        patent.title = "  ä¸€ç§æ–°å‹å†œä¸šæœºæ¢°è£…ç½®  "  # æœ‰å¤šä½™ç©ºæ ¼
        patent.abstract = "æœ¬å‘æ˜æ¶‰åŠ<b>å†œä¸šæœºæ¢°</b>è£…ç½®ï¼Œå…·æœ‰<i>åˆ›æ–°æ€§</i>ç‰¹å¾..."  # æœ‰HTMLæ ‡ç­¾
        patent.country = "ä¸­å›½"  # ä¸­æ–‡å›½å®¶å
        patent.status = "pending"  # è‹±æ–‡çŠ¶æ€ï¼ˆè¿™é‡Œä¼šåœ¨æ ‡å‡†åŒ–æ—¶å¤„ç†ï¼‰
        patent.keywords = ["  å†œä¸š  ", "æœºæ¢°", "", "è£…ç½®  ", "è‡ªåŠ¨åŒ–"]  # æœ‰ç©ºæ ¼å’Œç©ºå€¼
        patent.inventors[0].name = "  å¼  ä¸‰  "
        patent.inventors[0].normalized_name = "  å¼  ä¸‰  "
        
        print(f"ğŸ“ æ ‡å‡†åŒ–å‰:")
        print(f"   ç”³è¯·å·: '{patent.application_number}'")
        print(f"   æ ‡é¢˜: '{patent.title}'")
        print(f"   æ‘˜è¦: '{patent.abstract[:50]}...'")
        print(f"   å›½å®¶: '{patent.country}'")
        print(f"   çŠ¶æ€: '{patent.status}'")
        print(f"   å…³é”®è¯: {patent.keywords}")
        print(f"   å‘æ˜äºº: '{patent.inventors[0].name}'")
        
        # æ‰§è¡Œæ ‡å‡†åŒ–
        standardized = await standardizer.standardize_patent(patent)
        
        print(f"\nâœ¨ æ ‡å‡†åŒ–å:")
        print(f"   ç”³è¯·å·: '{standardized.application_number}'")
        print(f"   æ ‡é¢˜: '{standardized.title}'")
        print(f"   æ‘˜è¦: '{standardized.abstract[:50]}...'")
        print(f"   å›½å®¶: '{standardized.country}'")
        print(f"   çŠ¶æ€: '{standardized.status}'")
        print(f"   å…³é”®è¯: {standardized.keywords}")
        print(f"   å‘æ˜äºº: '{standardized.inventors[0].normalized_name}'")
        print(f"   è´¨é‡è¯„åˆ†: {standardized.data_quality_score:.2f}")
        
        print("âœ… æ•°æ®æ ‡å‡†åŒ–æµ‹è¯•æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®æ ‡å‡†åŒ–æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


async def test_deduplication():
    """æµ‹è¯•å»é‡åŠŸèƒ½."""
    print("\nğŸ§ª æµ‹è¯•å»é‡åŠŸèƒ½...")
    
    try:
        deduplicator = PatentDeduplicator()
        
        # åˆ›å»ºåŒ…å«é‡å¤æ•°æ®çš„ä¸“åˆ©åˆ—è¡¨
        patents = []
        
        # åŸå§‹ä¸“åˆ©
        patent1 = PatentData(
            application_number="CN202310123456.7",
            title="å†œä¸šæœºæ¢°è£…ç½®",
            abstract="è¿™æ˜¯ä¸€ä¸ªå†œä¸šæœºæ¢°è£…ç½®çš„è¯¦ç»†æè¿°ï¼Œå…·æœ‰åˆ›æ–°çš„æŠ€æœ¯ç‰¹å¾...",
            applicants=[PatentApplicant(name="å…¬å¸A", normalized_name="å…¬å¸A")],
            inventors=[PatentInventor(name="å‘æ˜äººA", normalized_name="å‘æ˜äººA")],
            application_date=datetime(2023, 1, 15),
            country="CN",
            status="ç”³è¯·ä¸­",
            data_source="source1",
            data_quality_score=0.9
        )
        patents.append(patent1)
        
        # å®Œå…¨ç›¸åŒçš„ä¸“åˆ©ï¼ˆåº”è¯¥è¢«å»é‡ï¼‰
        patent2 = PatentData(
            application_number="CN202310123456.7",
            title="å†œä¸šæœºæ¢°è£…ç½®",
            abstract="è¿™æ˜¯ä¸€ä¸ªå†œä¸šæœºæ¢°è£…ç½®çš„è¯¦ç»†æè¿°ï¼Œå…·æœ‰åˆ›æ–°çš„æŠ€æœ¯ç‰¹å¾...",
            applicants=[PatentApplicant(name="å…¬å¸A", normalized_name="å…¬å¸A")],
            inventors=[PatentInventor(name="å‘æ˜äººA", normalized_name="å‘æ˜äººA")],
            application_date=datetime(2023, 1, 15),
            country="CN",
            status="ç”³è¯·ä¸­",
            data_source="source2",
            data_quality_score=0.8  # è´¨é‡æ›´ä½ï¼Œåº”è¯¥è¢«ç§»é™¤
        )
        patents.append(patent2)
        
        # ä¸åŒçš„ä¸“åˆ©
        patent3 = PatentData(
            application_number="CN202310123457.8",
            title="å¦ä¸€ç§å†œä¸šæœºæ¢°è£…ç½®",
            abstract="è¿™æ˜¯å¦ä¸€ç§å†œä¸šæœºæ¢°è£…ç½®çš„è¯¦ç»†æè¿°ï¼Œå…·æœ‰ä¸åŒçš„æŠ€æœ¯ç‰¹å¾...",
            applicants=[PatentApplicant(name="å…¬å¸B", normalized_name="å…¬å¸B")],
            inventors=[PatentInventor(name="å‘æ˜äººB", normalized_name="å‘æ˜äººB")],
            application_date=datetime(2023, 2, 15),
            country="CN",
            status="ç”³è¯·ä¸­",
            data_source="source1",
            data_quality_score=0.85
        )
        patents.append(patent3)
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = PatentDataset(
            patents=patents,
            search_keywords=["å†œä¸šæœºæ¢°"],
            data_sources=["source1", "source2"]
        )
        
        print(f"ğŸ“Š å»é‡å‰: {len(dataset.patents)} ä¸ªä¸“åˆ©")
        for i, patent in enumerate(dataset.patents):
            print(f"   {i+1}. {patent.application_number} (è´¨é‡: {patent.data_quality_score:.2f})")
        
        # æ‰§è¡Œå»é‡
        deduplicated_dataset, removed_count = await deduplicator.deduplicate_dataset(dataset)
        
        print(f"\nğŸ”„ å»é‡å: {len(deduplicated_dataset.patents)} ä¸ªä¸“åˆ© (ç§»é™¤äº† {removed_count} ä¸ªé‡å¤é¡¹)")
        for i, patent in enumerate(deduplicated_dataset.patents):
            print(f"   {i+1}. {patent.application_number} (è´¨é‡: {patent.data_quality_score:.2f})")
        
        print("âœ… å»é‡åŠŸèƒ½æµ‹è¯•æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ å»é‡åŠŸèƒ½æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


async def test_quality_control():
    """æµ‹è¯•è´¨é‡æ§åˆ¶."""
    print("\nğŸ§ª æµ‹è¯•è´¨é‡æ§åˆ¶...")
    
    try:
        quality_controller = PatentQualityController()
        
        patents = []
        
        # é«˜è´¨é‡ä¸“åˆ©
        good_patent = PatentData(
            application_number="CN202310123456.7",
            title="ä¸€ç§æ–°å‹å†œä¸šæœºæ¢°è£…ç½®åŠå…¶æ§åˆ¶æ–¹æ³•",
            abstract="æœ¬å‘æ˜æ¶‰åŠä¸€ç§æ–°å‹å†œä¸šæœºæ¢°è£…ç½®åŠå…¶æ§åˆ¶æ–¹æ³•ï¼ŒåŒ…æ‹¬ä¸»ä½“ç»“æ„ã€ä¼ åŠ¨ç³»ç»Ÿã€æ§åˆ¶ç³»ç»Ÿå’Œä¼ æ„Ÿå™¨ç³»ç»Ÿç­‰éƒ¨åˆ†ï¼Œèƒ½å¤Ÿå®ç°è‡ªåŠ¨åŒ–ä½œä¸šå’Œæ™ºèƒ½æ§åˆ¶ã€‚",
            applicants=[PatentApplicant(name="æµ‹è¯•ç§‘æŠ€æœ‰é™å…¬å¸", normalized_name="æµ‹è¯•ç§‘æŠ€ Co., Ltd.")],
            inventors=[PatentInventor(name="å¼ ä¸‰", normalized_name="å¼ ä¸‰"), PatentInventor(name="æå››", normalized_name="æå››")],
            application_date=datetime(2023, 1, 15),
            publication_date=datetime(2023, 7, 15),
            classifications=[PatentClassification(ipc_class="A01B 1/00")],
            country="CN",
            status="å·²å…¬å¼€",
            technical_field="å†œä¸šæœºæ¢°",
            data_source="test_source",
            keywords=["å†œä¸š", "æœºæ¢°", "è‡ªåŠ¨åŒ–", "æ§åˆ¶"]
        )
        patents.append(good_patent)
        
        # ä¸­ç­‰è´¨é‡ä¸“åˆ©ï¼ˆç¼ºå°‘ä¸€äº›ä¿¡æ¯ï¼‰
        medium_patent = PatentData(
            application_number="CN202310123457.8",
            title="å†œä¸šè®¾å¤‡è£…ç½®ç³»ç»Ÿ",  # å¢åŠ é•¿åº¦ä»¥æ»¡è¶³éªŒè¯
            abstract="ä¸€ç§å†œä¸šè®¾å¤‡è£…ç½®ç³»ç»Ÿçš„è¯¦ç»†æè¿°å’ŒæŠ€æœ¯ç‰¹å¾...",  # å¢åŠ é•¿åº¦ä»¥æ»¡è¶³éªŒè¯
            applicants=[PatentApplicant(name="å…¬å¸B", normalized_name="å…¬å¸B")],
            inventors=[PatentInventor(name="ç‹äº”", normalized_name="ç‹äº”")],
            application_date=datetime(2023, 2, 15),
            country="CN",
            status="ç”³è¯·ä¸­",
            data_source="test_source"
            # ç¼ºå°‘åˆ†ç±»ã€æŠ€æœ¯é¢†åŸŸç­‰ä¿¡æ¯
        )
        patents.append(medium_patent)
        
        # ä½è´¨é‡ä¸“åˆ©ï¼ˆå…ˆåˆ›å»ºæœ‰æ•ˆå¯¹è±¡ï¼Œç„¶åæ‰‹åŠ¨è®¾ç½®é—®é¢˜å­—æ®µï¼‰
        bad_patent = PatentData(
            application_number="CN202310123458.9",
            title="æµ‹è¯•ä¸“åˆ©æ ‡é¢˜",
            abstract="è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ä¸“åˆ©çš„æ‘˜è¦æè¿°...",
            applicants=[PatentApplicant(name="æµ‹è¯•å…¬å¸", normalized_name="æµ‹è¯•å…¬å¸")],
            inventors=[PatentInventor(name="æµ‹è¯•å‘æ˜äºº", normalized_name="æµ‹è¯•å‘æ˜äºº")],
            application_date=datetime(2023, 1, 15),
            country="CN",
            status="ç”³è¯·ä¸­",
            data_source="test_source"
        )
        
        # æ‰‹åŠ¨è®¾ç½®é—®é¢˜å­—æ®µï¼ˆç»•è¿‡PydanticéªŒè¯ï¼‰
        bad_patent.application_number = ""  # ç©ºç”³è¯·å·
        bad_patent.title = "çŸ­"  # æ ‡é¢˜å¤ªçŸ­
        bad_patent.abstract = "çŸ­æ‘˜è¦"  # æ‘˜è¦å¤ªçŸ­
        bad_patent.applicants = []  # æ²¡æœ‰ç”³è¯·äºº
        bad_patent.inventors = []  # æ²¡æœ‰å‘æ˜äºº
        bad_patent.country = ""  # ç©ºå›½å®¶
        patents.append(bad_patent)
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = PatentDataset(
            patents=patents,
            search_keywords=["å†œä¸š"],
            data_sources=["test_source"]
        )
        
        print(f"ğŸ“Š è´¨é‡éªŒè¯å‰: {len(dataset.patents)} ä¸ªä¸“åˆ©")
        
        # æ‰§è¡Œè´¨é‡éªŒè¯
        report = await quality_controller.validate_dataset(dataset)
        
        print(f"\nğŸ“‹ è´¨é‡æŠ¥å‘Š:")
        print(f"   æ€»è®°å½•æ•°: {report.total_records}")
        print(f"   æœ‰æ•ˆè®°å½•: {report.valid_records}")
        print(f"   æ— æ•ˆè®°å½•: {report.invalid_records}")
        print(f"   æ•´ä½“è´¨é‡è¯„åˆ†: {report.quality_score:.2f}")
        print(f"   å®Œæ•´æ€§è¯„åˆ†: {report.completeness_score:.2f}")
        print(f"   å‡†ç¡®æ€§è¯„åˆ†: {report.accuracy_score:.2f}")
        print(f"   ä¸€è‡´æ€§è¯„åˆ†: {report.consistency_score:.2f}")
        
        if report.missing_fields:
            print(f"   ç¼ºå¤±å­—æ®µç»Ÿè®¡: {report.missing_fields}")
        
        if report.invalid_formats:
            print(f"   æ ¼å¼é”™è¯¯ç»Ÿè®¡: {report.invalid_formats}")
        
        if report.data_anomalies:
            print(f"   æ•°æ®å¼‚å¸¸: {len(report.data_anomalies)} ä¸ª")
            for anomaly in report.data_anomalies[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                print(f"     - {anomaly}")
        
        if report.recommendations:
            print(f"   æ”¹è¿›å»ºè®®:")
            for rec in report.recommendations[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                print(f"     - {rec}")
        
        print("âœ… è´¨é‡æ§åˆ¶æµ‹è¯•æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ è´¨é‡æ§åˆ¶æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


async def test_complete_processing():
    """æµ‹è¯•å®Œæ•´çš„æ•°æ®å¤„ç†æµç¨‹."""
    print("\nğŸ§ª æµ‹è¯•å®Œæ•´æ•°æ®å¤„ç†æµç¨‹...")
    
    try:
        processor = PatentDataProcessor()
        
        # åˆ›å»ºåŒ…å«å„ç§é—®é¢˜çš„æµ‹è¯•æ•°æ®é›†
        patents = []
        
        # éœ€è¦æ ‡å‡†åŒ–çš„ä¸“åˆ©
        patent1 = PatentData(
            application_number="CN202310123456.7",
            title="å†œä¸šæœºæ¢°è£…ç½®",
            abstract="æœ¬å‘æ˜æ¶‰åŠå†œä¸šæœºæ¢°è£…ç½®ï¼Œå…·æœ‰åˆ›æ–°ç‰¹å¾...",
            applicants=[PatentApplicant(name="æµ‹è¯•å…¬å¸æœ‰é™å…¬å¸", normalized_name="æµ‹è¯•å…¬å¸æœ‰é™å…¬å¸")],
            inventors=[PatentInventor(name="å¼ ä¸‰", normalized_name="å¼ ä¸‰")],
            application_date=datetime(2023, 1, 15),
            country="CN",
            status="ç”³è¯·ä¸­",
            data_source="source1",
            data_quality_score=0.9
        )
        
        # æ‰‹åŠ¨è®¾ç½®éœ€è¦æ ‡å‡†åŒ–çš„å­—æ®µ
        patent1.application_number = "cn202310123456.7"  # å°å†™
        patent1.title = "  å†œä¸šæœºæ¢°è£…ç½®  "  # å¤šä½™ç©ºæ ¼
        patent1.abstract = "æœ¬å‘æ˜æ¶‰åŠ<b>å†œä¸šæœºæ¢°</b>è£…ç½®ï¼Œå…·æœ‰åˆ›æ–°ç‰¹å¾..."  # HTMLæ ‡ç­¾
        patent1.country = "ä¸­å›½"  # ä¸­æ–‡å›½å®¶å
        patents.append(patent1)
        
        # é‡å¤ä¸“åˆ©ï¼ˆè´¨é‡æ›´ä½ï¼‰
        patent2 = PatentData(
            application_number="CN202310123456.7",  # æ ‡å‡†åŒ–åä¼šä¸patent1ç›¸åŒ
            title="å†œä¸šæœºæ¢°è£…ç½®",
            abstract="æœ¬å‘æ˜æ¶‰åŠå†œä¸šæœºæ¢°è£…ç½®ï¼Œå…·æœ‰åˆ›æ–°ç‰¹å¾...",
            applicants=[PatentApplicant(name="æµ‹è¯•å…¬å¸ Co., Ltd.", normalized_name="æµ‹è¯•å…¬å¸ Co., Ltd.")],
            inventors=[PatentInventor(name="å¼ ä¸‰", normalized_name="å¼ ä¸‰")],
            application_date=datetime(2023, 1, 15),
            country="CN",
            status="ç”³è¯·ä¸­",
            data_source="source2",
            data_quality_score=0.7  # è´¨é‡æ›´ä½
        )
        patents.append(patent2)
        
        # æ­£å¸¸ä¸“åˆ©
        patent3 = PatentData(
            application_number="CN202310123457.8",
            title="å¦ä¸€ç§å†œä¸šæœºæ¢°è£…ç½®",
            abstract="è¿™æ˜¯å¦ä¸€ç§å†œä¸šæœºæ¢°è£…ç½®çš„è¯¦ç»†æè¿°ï¼Œå…·æœ‰ä¸åŒçš„æŠ€æœ¯ç‰¹å¾å’Œåº”ç”¨åœºæ™¯...",
            applicants=[PatentApplicant(name="å¦ä¸€å®¶å…¬å¸", normalized_name="å¦ä¸€å®¶å…¬å¸")],
            inventors=[PatentInventor(name="æå››", normalized_name="æå››")],
            application_date=datetime(2023, 2, 15),
            country="CN",
            status="ç”³è¯·ä¸­",
            data_source="source1",
            data_quality_score=0.85
        )
        patents.append(patent3)
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = PatentDataset(
            patents=patents,
            search_keywords=["å†œä¸šæœºæ¢°"],
            data_sources=["source1", "source2"]
        )
        
        print(f"ğŸ“Š å¤„ç†å‰: {len(dataset.patents)} ä¸ªä¸“åˆ©")
        
        # æ‰§è¡Œå®Œæ•´å¤„ç†æµç¨‹
        processed_dataset, quality_report = await processor.process_dataset(
            dataset,
            standardize=True,
            deduplicate=True,
            validate=True
        )
        
        print(f"\nğŸ”„ å¤„ç†å: {len(processed_dataset.patents)} ä¸ªä¸“åˆ©")
        
        if quality_report:
            print(f"\nğŸ“‹ æœ€ç»ˆè´¨é‡æŠ¥å‘Š:")
            print(f"   æ€»è®°å½•æ•°: {quality_report.total_records}")
            print(f"   æœ‰æ•ˆè®°å½•: {quality_report.valid_records}")
            print(f"   é‡å¤è®°å½•: {quality_report.duplicate_records}")
            print(f"   æ•´ä½“è´¨é‡è¯„åˆ†: {quality_report.quality_score:.2f}")
        
        # æ˜¾ç¤ºå¤„ç†åçš„ä¸“åˆ©ä¿¡æ¯
        print(f"\nğŸ“„ å¤„ç†åçš„ä¸“åˆ©:")
        for i, patent in enumerate(processed_dataset.patents):
            print(f"   {i+1}. {patent.application_number}")
            print(f"      æ ‡é¢˜: {patent.title}")
            print(f"      å›½å®¶: {patent.country}")
            print(f"      çŠ¶æ€: {patent.status}")
            print(f"      è´¨é‡: {patent.data_quality_score:.2f}")
        
        # è®¡ç®—æ•°æ®é›†è´¨é‡æŒ‡æ ‡
        metrics = processed_dataset.calculate_quality_metrics()
        print(f"\nğŸ“ˆ æ•°æ®é›†è´¨é‡æŒ‡æ ‡:")
        print(f"   å¹³å‡è´¨é‡è¯„åˆ†: {metrics.get('average_quality_score', 0):.2f}")
        print(f"   é«˜è´¨é‡ä¸“åˆ©: {metrics.get('high_quality_count', 0)} ä¸ª")
        print(f"   ä¸­ç­‰è´¨é‡ä¸“åˆ©: {metrics.get('medium_quality_count', 0)} ä¸ª")
        print(f"   ä½è´¨é‡ä¸“åˆ©: {metrics.get('low_quality_count', 0)} ä¸ª")
        
        print("âœ… å®Œæ•´æ•°æ®å¤„ç†æµç¨‹æµ‹è¯•æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ å®Œæ•´æ•°æ®å¤„ç†æµç¨‹æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°."""
    print("ğŸš€ å¼€å§‹ä¸“åˆ©æ•°æ®å¤„ç†å’Œè´¨é‡æ§åˆ¶åŠŸèƒ½æµ‹è¯•\n")
    
    tests = [
        ("ä¸“åˆ©æ•°æ®æ¨¡å‹", test_patent_data_models),
        ("æ•°æ®æ ‡å‡†åŒ–", test_data_standardization),
        ("å»é‡åŠŸèƒ½", test_deduplication),
        ("è´¨é‡æ§åˆ¶", test_quality_control),
        ("å®Œæ•´å¤„ç†æµç¨‹", test_complete_processing),
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            result = await test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name}æµ‹è¯•å‡ºç°å¼‚å¸¸: {str(e)}")
            results.append((test_name, False))
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "="*60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
    print("="*60)
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"   {test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\nğŸ¯ æ€»ä½“ç»“æœ: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†ï¼ä¸“åˆ©æ•°æ®å¤„ç†å’Œè´¨é‡æ§åˆ¶åŠŸèƒ½å®ç°æ­£ç¡®ã€‚")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°ã€‚")
    
    return passed == total


if __name__ == "__main__":
    asyncio.run(main())